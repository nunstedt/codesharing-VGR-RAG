This could be facilitated, for example, by machine-brain interfaces or virtual reality as they allow for a higher degree of control of what stimuli are presented to persons, insofar as they may materially distort their behaviour in a significantly harmful manner. In addition, AI systems may also otherwise exploit the vulnerabilities of a person or a specific group of persons due to their age, disability within the meaning of Directive  (EU)  2019/882  of  the  European  Parliament  and  of  the  Council ( 16 ),  or  a  specific  social  or  economic situation  that  is  likely  to  make  those  persons  more  vulnerable  to  exploitation  such  as  persons  living  in  extreme poverty, ethnic or religious minorities. Such AI systems can be placed on the market, put into service or used with the  objective  to  or  the  effect  of  materially  distorting  the  behaviour  of  a  person  and  in  a  manner  that  causes  or  is reasonably likely to cause significant harm to that or another person or groups of persons, including harms that may be  accumulated  over  time  and  should  therefore  be  prohibited.  It  may  not  be  possible  to  assume  that  there  is  an
( 16 ) Directive  (EU)  2019/882  of  the  European  Parliament  and  of  the  Council  of  17  April  2019  on  the  accessibility  requirements  for products and services  (OJ  L  151,  ,  p.  70).
intention to distort behaviour  where the distortion results from factors external to the AI system which are outside the control of the provider or the deployer, namely factors that may not be reasonably foreseeable and therefore not possible for the provider or the deployer of the AI system to mitigate. In any case, it is not necessary for the provider or  the  deployer  to  have  the  intention  to  cause  significant  harm,  provided  that  such  harm  results  from  the manipulative or exploitative AI-enabled practices. The prohibitions for such AI practices are complementary to the provisions contained in Directive 2005/29/EC of the European Parliament and of the Council ( 17 ), in particular unfair commercial practices leading to economic or financial harms to consumers are prohibited under all circumstances, irrespective of whether they are put in place through AI systems or otherwise. The prohibitions of manipulative and exploitative practices in this Regulation should not affect lawful practices in the context of medical treatment such as psychological  treatment  of  a  mental  disease  or  physical  rehabilitation,  when  those  practices  are  carried  out  in accordance with the applicable law and medical standards, for example explicit consent of  the individuals or  their legal  representatives.  In  addition,  common  and  legitimate  commercial  practices,  for  example  in  the  field  of advertising,  that  comply  with  the  applicable  law  should  not,  in  themselves,  be  regarded  as  constituting  harmful manipulative AI-enabled  practices.
- (30) Biometric categorisation  systems  that  are  based  on  natural  persons'  biometric  data,  such  as  an  individual  person's face  or  fingerprint,  to  deduce  or  infer  an  individuals'  political  opinions,  trade  union  membership,  religious  or philosophical beliefs, race, sex life or sexual orientation should be prohibited. That prohibition should not cover the lawful  labelling,  filtering  or  categorisation  of  biometric  data  sets  acquired  in  line  with  Union  or  national  law according  to  biometric  data,  such  as  the  sorting  of  images  according  to  hair  colour  or  eye  colour,  which  can  for example be used in the area of  law enforcement.
- (31) AI  systems  providing  social  scoring  of  natural  persons  by  public  or  private  actors  may  lead  to  discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify natural persons or groups thereof on the basis of multiple data points related to their social behaviour in multiple contexts or known, inferred or predicted personal or personality characteristics over certain periods of time. The social score obtained from such AI systems may lead to  the  detrimental or  unfavourable treatment of natural persons or  whole groups thereof in social contexts, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is  disproportionate  or  unjustified  to  the  gravity  of  their  social  behaviour.  AI  systems  entailing  such  unacceptable scoring  practices  and  leading  to  such  detrimental  or  unfavourable  outcomes  should  therefore  be  prohibited.  That prohibition should not affect lawful evaluation practices of natural persons that are carried out for a specific purpose in  accordance  with  Union  and  national  law.
- (32) The use of AI systems for 'real-time' remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement is particularly intrusive to the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. Such possible biased results and discriminatory effects are particularly relevant with regard to age,  ethnicity,  race,  sex  or  disabilities.  In  addition,  the  immediacy  of  the  impact  and  the  limited  opportunities  for further checks or corrections in relation to the use of such systems operating in real-time carry heightened risks for the  rights  and  freedoms  of  the  persons  concerned  in  the  context  of,  or  impacted  by,  law  enforcement  activities.
- (33) The use of those systems for the purpose of  law enforcement should therefore be prohibited, except in exhaustively listed and narrowly defined situations, where the use is strictly necessary to achieve a substantial public interest, the importance of which outweighs the risks. Those situations involve the search for certain victims of crime including missing persons; certain threats to the life or to the physical safety of natural persons or of a terrorist attack; and the localisation or identification of perpetrators or suspects of the criminal offences listed in an annex to this Regulation, where those criminal offences are punishable in the Member State concerned by a custodial sentence or a detention
( 17 ) Directive  2005/29/EC  of  the  European  Parliament  and  of  the  Council  of  11  May  2005  concerning  unfair  business-to-consumer commercial  practices  in  the  internal  market  and  amending  Council  Directive  84/450/EEC,  Directives  97/7/EC,  98/27/EC  and 2002/65/EC of the European Parliament and of the Council and Regulation (EC) No 2006/2004 of the European Parliament and of the  Council  ('Unfair  Commercial  Practices  Directive')  (OJ  L  149,  ,  p.  22).
order  for  a  maximum  period  of  at  least  four  years  and  as  they  are  defined  in  the  law  of  that  Member  State.  Such a  threshold  for  the  custodial  sentence  or  detention  order  in  accordance  with  national  law  contributes  to  ensuring that the offence should be serious enough to potentially justify the use of 'real-time' remote biometric identification systems. Moreover, the list of criminal offences provided in an annex to this Regulation is based on the 32 criminal offences  listed  in  the  Council  Framework  Decision  2002/584/JHA ( 18 ),  taking  into  account  that  some  of  those offences are, in practice, likely to be more relevant than others, in that the recourse to 'real-time' remote biometric identification could, foreseeably, be necessary and proportionate to highly varying degrees for  the practical pursuit of  the  localisation  or  identification  of  a  perpetrator  or  suspect  of  the  different  criminal  offences  listed  and  having regard  to  the likely differences  in the  seriousness,  probability and  scale  of the  harm  or  possible  negative consequences. An imminent threat to life or  the physical safety of natural persons could also result from a serious disruption of critical infrastructure, as defined in Article 2, point (4) of Directive (EU) 2022/2557 of the European Parliament and of the Council ( 19 ), where the disruption or destruction of such critical infrastructure would result in an imminent threat to life or the physical safety of a person, including through serious harm to the provision of basic supplies  to  the  population  or  to  the  exercise  of  the  core  function  of  the  State.  In  addition,  this  Regulation  should preserve  the  ability  for  law  enforcement,  border  control,  immigration  or  asylum  authorities  to  carry  out  identity checks in the presence of the person concerned in accordance with the conditions set out in Union and national law for such checks. In particular, law enforcement, border control, immigration or asylum authorities should be able to use  information  systems,  in  accordance  with  Union  or  national  law,  to  identify  persons  who,  during  an  identity check,  either  refuse  to  be  identified  or  are  unable  to  state  or  prove  their  identity,  without  being  required  by  this Regulation to obtain prior authorisation. This could be, for example, a person involved in a crime, being unwilling, or  unable  due  to  an  accident  or  a  medical  condition,  to  disclose  their  identity  to  law  enforcement  authorities.
- (34) In  order  to  ensure  that  those  systems  are  used  in  a  responsible  and  proportionate  manner,  it  is  also  important  to establish that, in each of those exhaustively listed and narrowly defined situations, certain elements should be taken into account, in particular as regards the nature of  the situation giving rise to the request and the consequences of the use for the rights and freedoms of all persons concerned and the safeguards and conditions provided for with the use.  In  addition,  the  use  of  'real-time'  remote  biometric  identification  systems  in  publicly  accessible  spaces  for  the purpose of  law  enforcement should be  deployed  only to confirm  the  specifically  targeted individual's  identity  and should be limited to what is strictly necessary concerning the period of time, as well as the geographic and personal scope, having regard in particular to the evidence or indications regarding the threats, the victims or perpetrator. The use of the real-time remote biometric identification system in publicly accessible spaces should be authorised only if the relevant law enforcement authority has completed a fundamental rights impact assessment and, unless provided otherwise  in  this  Regulation,  has  registered  the  system  in  the  database  as  set  out  in  this  Regulation.  The  reference database  of  persons  should  be  appropriate  for  each  use  case  in  each  of  the  situations  mentioned  above.
- (35) Each use of a 'real-time' remote biometric identification system in publicly accessible spaces for the purpose of  law enforcement should be subject to an express and specific authorisation by a judicial authority or by an independent administrative  authority of  a  Member  State  whose  decision  is  binding.  Such  authorisation  should,  in  principle,  be obtained prior  to the use  of  the  AI  system with  a view  to identifying  a  person  or  persons.  Exceptions to  that  rule should be allowed in duly justified situations on grounds of urgency, namely in situations where the need to use the systems  concerned  is  such  as  to  make  it  effectively  and  objectively  impossible  to  obtain  an  authorisation  before commencing the use of the AI system. In such situations of urgency, the use of the AI system should be restricted to the absolute minimum necessary and should be subject to appropriate safeguards and conditions, as determined in national law and specified in the context of each individual urgent use case by the law enforcement authority itself. In addition, the law enforcement authority should in such situations request such authorisation while providing the reasons for not having been able to request it earlier, without undue delay and at the latest within 24 hours. If such an authorisation is rejected, the use of real-time biometric identification systems linked to that authorisation should cease with immediate effect and all the data related to such use should be discarded and deleted. Such data includes
( 18 ) Council  Framework  Decision  2002/584/JHA  of  13  June  2002  on  the  European  arrest  warrant  and  the  surrender  procedures between Member States (OJ L 190, , p. 1).
( 19 ) Directive (EU) 2022/2557 of the European Parliament and of the Council of 14 December 2022 on the resilience of critical entities and repealing  Council  Directive  2008/114/EC  (OJ  L  333,  ,  p.  164).
input data directly acquired by an AI system in the course of the use of such system as well as the results and outputs of the use linked to that authorisation. It should not include input that is legally acquired in accordance with another Union or national law. In any case, no decision producing an adverse legal effect on a person should be taken based solely on  the  output  of  the  remote  biometric  identification  system.
- (36) In order to carry out their tasks in accordance with the requirements set out in this Regulation as well as in national rules, the relevant market surveillance authority and the national data protection authority should be notified of each use of the real-time biometric identification system. Market surveillance authorities and the national data protection authorities  that  have  been  notified  should  submit  to  the  Commission  an  annual  report  on  the  use  of  real-time biometric  identification  systems.
- (37) Furthermore, it is appropriate to provide, within the exhaustive framework set by this Regulation that such use in the territory of a Member State in accordance with this Regulation should only be possible where and in as far as the Member State concerned has decided to expressly provide for the possibility to authorise such use in its detailed rules of national law. Consequently, Member States remain free under this Regulation not to provide for such a possibility at all or to only provide for such a possibility in respect of some of the objectives capable of justifying authorised use identified  in  this  Regulation.  Such  national  rules  should  be  notified  to  the  Commission  within  30  days  of  their adoption.
- (38) The use of AI systems for real-time remote biometric identification of natural persons in publicly accessible spaces for  the  purpose  of  law  enforcement  necessarily  involves  the  processing  of  biometric  data.  The  rules  of  this Regulation that prohibit, subject to certain exceptions, such use, which are based on Article 16 TFEU, should apply as lex  specialis in  respect of  the  rules  on  the  processing  of  biometric  data  contained  in  Article  10  of  Directive  (EU) 2016/680,  thus  regulating  such  use  and  the  processing  of  biometric  data  involved  in  an  exhaustive  manner. Therefore, such use and processing should be possible only in as far as it is compatible with the framework set by this Regulation, without there being scope, outside that framework, for the competent authorities, where they act for purpose of law enforcement, to use such systems and process such data in connection thereto on the grounds listed in Article 10 of Directive (EU) 2016/680. In that context, this Regulation is not intended to provide the legal basis for the processing of personal data under Article 8 of Directive (EU) 2016/680. 