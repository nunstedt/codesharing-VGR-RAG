180 FRA,  # BigData. Discrimination in data supported decision making , Luxemburg, 2018, 14, p. 5.
(286) Article 5(1)(f) AI Act also provides that the prohibition in that provision does not apply to the labelling or filtering of  lawfully acquired  datasets in the area of  law enforcement 181 .
For example, this covers the use by a law enforcement authority of an AI system that allows labelling and filtering of a dataset suspected of containing child sexual abuse material. In a first step, law enforcement would use the support of AI systems to detect and redact sensitive data from images. Furthermore, filtering and labelling according to gender, age, biometric data such as eye and hair colour, scars and marking could help with identifying the victims or creating links with other cases. Similarly filtering and labelling abusers' hands based on specific characteristics such as length of fingers or any  distinguishing  markings  or  tattoos  to  help  with  identifying  possible  suspects  is permitted.
## . Interplay with other Union law
(287) AI  systems  intended  to  be  used  for  biometric  categorisation  according  to  sensitive attributes or characteristics protected under Article 9(1) GDPR on the basis of biometric data, in so far as these are not prohibited under this Regulation, are classified as highrisk 182 under the AI Act 183 .
(288) Article  5(1)(g)  AI  Act  further  restricts  the  possibilities  for  a  lawful  personal  data processing  under  Union  data  protection  law,  such  as  the  GDPR,  LED,  EUDPR.  In particular, Article 5(1)(g) AI Act excludes the possibilities for biometric categorisation of natural persons, based on their biometric data, as defined in the AI Act, to infer race, political opinions, trade union membership, religious or philosophical beliefs, sex life or  sexual  orientation,  subject  to  the  exception  for  labelling  or  filtering  of  lawfully acquired biometric data sets, including in the area of law enforcement, as described above.  Moreover,  the  prohibition  in  Article  5(1)(g)  AI  Act  is  consistent  with Article 11(3) LED, which explicitly prohibits any 'profiling' that results in discrimination on the basis of special categories of personal data, such as race, ethnic origin, sexual orientation, political opinion, or religious beliefs.
## 9. ARTICLE 5(1)(H) AI ACT -REAL-TIME REMOTE BIOMETRIC IDENTIFICATION (RBI) SYSTEMS FOR LAW ENFORCEMENT PURPOSES
(289) Article 5(1)(h) AI Act prohibits the use of real-time RBI systems in publicly accessible spaces for law enforcement purposes, subject to limited exceptions exhaustively set out in the AI Act. Specifically, Article 5(1)(h)(i)-(iii) AI Act envisages three situations in which  the  use  of  such  systems  may  be  permitted  where  authorised  by  national
181 The AI Act concerning the use of biometric categorisation systems for law enforcement is based on Article 16 TFEU. See also Recital 3
AI Act.
182 Recital 54 and Annex III, point 1 letter b) AI Act.
183 Recital 54 and Annex III, point 1 letter b). AI Act.
legislation and where the conditions and safeguards of Article 5(2) to (7) AI Act are met.
- (290) In accordance with Article 5(5) AI Act, Member States are free to decide whether and in which of the three situations the use of real-time RBI systems in publicly accessible spaces for law enforcement purposes is permitted in their territory. In the absence of national legislation allowing and regulating such use, law enforcement authorities and entities  acting  on  their  behalf  may  not  deploy  such  systems  for  law  enforcement purposes.  The  existence  of  national  legislation  that  complies  with  the  relevant requirements of the AI Act is therefore a pre-requisite of such use.
- (291) Article  5(1)(h)  AI  Act  only  prohibits  the  use  of  real-time  RBI  systems  in  publicly accessible spaces for law enforcement purposes, so that only deployers of such systems are concerned by that provision. The placing on the market and the putting into service of such systems, as well as the use of other RBI systems, is not prohibited, but subject to the rules for high-risk AI systems in accordance with Article 6(2) and point a) of Annex  III  AI  Act 184 .  Where  a  Member  States  authorises  the  use  of  real-time  RBI systems in publicly accessible spaces for law enforcement purposes for any of the three objectives listed in Article 5(1)(h) AI Act, the rules for high-risk AI systems also apply to that use.
- (292) Finally, specific rules apply to the retrospective use of RBI systems for law enforcement purposes. Such non-real-time use is not prohibited, but subject to additional safeguards for the deployment of high-risk AI systems (Article 26(10) AI Act).
## . Rationale and objectives
(293) Recital  32  AI  Act  acknowledges  the  intrusive  nature  of  real-time  RBI  systems  in publicly accessible spaces for law enforcement purposes to the rights and freedoms of persons concerned, to the extent that it may affect the private life of a large part of the population,  evoke  a feeling  of  constant  surveillance,  and  indirectly  dissuade  the exercise  of  the  freedom  of  assembly  and  other  fundamental  rights.  Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. Such possibly biased results and discriminatory effects are particularly relevant with regard to age, ethnicity, race,  sex  or  disabilities.  In  addition,  the  immediacy  of  the  impact  and  the  limited opportunities for further checks or corrections in relation to the use of such systems operating in real-time carry heightened risks for the rights and freedoms of the persons concerned in the context of, or impacted by, law enforcement activities.'
(294) However, where the use of such systems is strictly necessary to achieve a substantial public interest and where the situations in which such use may occur are exhaustively listed and narrowly defined, that use outweighs the risks to fundamental rights (Recital
184 In addition, specific rules applicable to the retrospective use of RBI systems for a law enforcement purposes (Article 26(10) AI Act).
- 33 AI Act). To ensure that such systems are used in a 'responsible and proportionate manner',  their  use  is  subject  to  the  safeguards  and  the  specific  obligations  and requirements in Article 5(2)-(7) AI Act.
## . Main concepts and components of the prohibition
## Article 5(1)(h) AI Act
The following AI practices shall be prohibited:
h) the use of 'real-time' remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement, unless and in so far as such use is strictly necessary for one of the following objectives:
- i) the targeted search for specific victims of abduction, trafficking in human beings or sexual exploitation of human beings, as well as the search for missing persons;
ii) the prevention of a specific, substantial and imminent threat to the life or physical safety of natural persons or a genuine and present or genuine and foreseeable threat of a terrorist attack;
iii)  the localisation or identification of a person suspected of having committed a criminal offence, for the purpose of conducting a criminal investigation or prosecution or executing a criminal penalty for offences referred to in Annex II and punishable in the Member State concerned by a custodial sentence or a detention order for a maximum period of at least four years.
Point (h) of the first subparagraph is without prejudice to Article 9 of Regulation (EU) 2016/679 for the processing of biometric data for purposes other than law enforcement.
(295) Several cumulative conditions must be fulfilled for the prohibition in Article 5(1)(h) AI Act to apply:
- (i) The AI system must be a RBI system;
- (ii) The activity consists of the 'use' of that system;
- (iii)in 'real-time',
- (iv) in publicly accessible spaces, and
- (v) for law enforcement purposes.
(296) The second condition, i.e. the 'use' of the AI system, has been already  analysed in section . of these Guidelines. The other conditions listed above are further described and analysed below.
## . The Notion of Remote Biometric Identification
(297) Biometric recognition technologies detect, capture, and transform measurable physical characteristics  (such  as  eye  distance  and  size,  nose  length,  etc.)  or  behavioural
characteristics (such as gait or voice) into machine-readable biometric data (see section .d) above). These data are available in different forms: images or templates, which are  a  mathematical  representation  of  the  salient  features  of  an  individual,  used  for recognition purposes. Biometric recognition technologies are used for verification and identification purposes. 185
(298) According to Article 3(41) AI Act, a RBI system is
[a]n  AI  system  for  the  purpose  of  identifying  natural  persons,  without  their active involvement, typically at a distance through the comparison of a person's biometric data with the biometric data contained in a reference database.
(299) This  definition  covers  only  the  identification  functionality  of  biometric  recognition systems, which implies the absence of active involvement of the persons concerned (i.e. no active participation) and results in the capture of the characteristics of those persons typically at a distance. For identification performance, the captured biometric data are compared  with  biometric  data  already  stored  in  a  reference  database  (such  as  a repository, e.g. a criminal database containing facial images or templates of suspects).
## a) Identification purposes only
(300) The notion of 'biometric identification' is defined in Article 3(35) of the AI Act as the  automated  recognition  of  physical,  physiological  and  behavioural  or psychological  human features  for  the  purpose  of  establishing  the  identity  of a natural person by comparing biometric data of that individual to biometric data of individuals stored in a database.
(301) Recital 15 AI Act further clarifies that such human features may comprise the face, eye movement, body shape, voice, prosody, gait, posture, heart rate, blood pressure, odour, keystroke characteristics,
(302) AI systems used for following natural persons can also be included in the definition of biometric identification, for example to see in which direction a suspect escapes. This can be concluded from Article 5(1)(h)(iii) AI Act, that allows for the localisation of suspects of crimes. The localisation is possible when a person is being followed.
(303) AI systems that are intended to be used for biometric verification fall outside the scope of the prohibition in Article 5(1)(h) AI Act. 186 Biometric verification (or authentication) consists of comparing data presented at a sensor with another set of previously recorded data stored on a device, such as a smartphone, a passport, or an ID card. The purpose of biometric verification is to verify that a specific person is who they claim to be.
185 As defined by the biometrics community in ISO/IEC Standard 2382-37:2022 Information Technology - Vocabulary, Biometric recognition, Term .
186
Recital 17 AI Act.
An example of biometric verification is the comparison of a traveller's face scanned at an e-gate with the facial image contained in their passport.
## b) Remoteness
(304) According to Article 3(41) AI Act, remoteness implies the ability of biometric systems to identify individuals without their active involvement, typically at a distance through the  comparison of  a  person's  biometric  data  with  the  biometric  data  contained  in  a reference database.
(305) The use of biometric systems to confirm the identity of a natural person for the sole purpose of having access to a service, unlocking a device, or having security access to premises is excluded from the concept of 'remote' (Recital 15 AI Act). This modality is used, for example, in access control. 187
For example, a face identification system is deployed to enter a restricted area (e.g. power plant premises) through face scanning technology; the system compares the face  of  the  individual  presented  at  the  entrance  camera  with  a  reference  image contained in a reference database of persons allowed to enter the building.
(306) Recital  17  AI  Act  clarifies  that  this  exclusion  from  the  scope  of  the  prohibition  is justified by the fact that such systems are likely to have a minor impact on fundamental rights  of  natural  persons  as  compared  to  RBI  systems  which  may  be  used  for  the processing  of  the  biometric  data  of  a  large  number  of  persons  without  their  active involvement.   That  recital  further  clarifies  that  RBI  systems  are  typically  used  to perceive  multiple  persons  or  their  behaviour  simultaneously  in  order  to  facilitate significantly the identification of natural persons without their active involvement. For active involvement, it is not sufficient that persons are informed about the presence of cameras, but they need to step actively and consciously in front of a camera that is installed in a way fostering active participation.
## For example,
- - RBI systems that are used in cameras installed at walls or ceiling of metro stations for surveillance purposes. Such a system fulfils the condition of remoteness.
- - Systems that are used to give access to the metro station, such as biometric metro tickets, where persons are actively involved and consciously approach the biometric sensor to obtain access, do not fulfil that condition.
(307) Biometric recognition systems that process (contactless) fingerprints, gait, voice, DNA, keystrokes and  other (biometric) behavioural signals may  also  constitute  RBI systems. 188
## For example:
- -  A  voice  biometric  technology  system  may  be  deployed  to  identify  a  person speaking. 