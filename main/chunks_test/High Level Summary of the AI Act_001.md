## High-level summary of the AI Act
In this article we provide you with a high-level summary of the AI Act, selecting the parts which are most likely to be relevant to you regardless of who you are. We provide links to the original document where relevant so that you can always reference the Act text.
## Four-point summary
## The AI Act classifies AI according to its risk:
- • Unacceptable risk is prohibited (e.g. social scoring systems and manipulative AI).
- • Most of the text addresses high-risk AI systems, which are regulated.
- · A smaller section handles limited risk AI systems, subject to lighter transparency obligations: developers and deployers must ensure that end-users are aware that they are interacting with AI (chatbots and deepfakes).
- · Minimal risk is unregulated (including the majority of AI applications currently available on the EU single market, such as AI enabled video games and spam filters - at least in 2021; this is changing with generative AI).
## The majority of obligations fall on providers (developers) of high-risk AI systems.
- · Those that intend to place on the market or put into service high-risk AI systems in the EU, regardless of whether they are based in the EU or a third country.
- • And also third country providers where the high risk AI system's output is used in the EU.
## Deployers are natural or legal persons that deploy an AI system in a professional capacity, not a ff ected end-users.
- · Deployers of high-risk AI systems have some obligations, though less than providers (developers).
- · This applies to deployers located in the EU, and third country users where the AI system's output is used in the EU.
## General purpose AI (GPAI):
- · All GPAI model providers must provide technical documentation, instructions for use, comply with the Copyright Directive, and publish a summary about the content used for training.
- · Free and open licence GPAI model providers only need to comply with copyright and publish the training data summary, unless they present a systemic risk.
- · All providers of GPAI models that present a systemic risk - open or closed - must also conduct model evaluations, adversarial testing, track and report serious incidents and ensure cybersecurity protections.
## Prohibited AI systems (Chapter II, Art. 5)
## AI systems:
- ∞ deploying subliminal, manipulative, or deceptive techniques to  distort  behaviour and impair informed decision-making, causing significant harm.
- ∞ exploiting vulnerabilities related to age, disability, or socio-economic circumstances to distort behaviour, causing significant harm.
- ∞ social scoring , i.e., evaluating or classifying individuals or groups based on social behaviour or personal traits, causing detrimental or unfavourable treatment of those people.
- ∞ assessing the risk of an individual committing criminal offenses solely based on profiling or personality  traits,  except  when  used  to  augment  human  assessments  based  on  objective, verifiable facts directly linked to criminal activity.
