7.
110 Art 3(52) AI Act does contain a definition of 'profiling' which cross-refers to the definition in Art 4(4) GDPR.
111 In particular, the prohibition of individual crime risk prediction in Article 5(1)(d) AI Act, which does refer to 'profiling', and in certain instances emotion recognition and biometric categorisation in Article 5(1)(f) and (g) AI Act.
112 Article 29 Working Party, Guidelines on Automated individual decision making and Profiling for the purposes of Regulation 2016/679, WP251rev.01, , p. 7.
For  example,  in  the SCHUFA I judgment,  the  CJEU  examined  a creditworthiness scoring system used in Germany. 113 In that case, the 'score' generated by the computer programme was a 'probability value' concerning the ability of a person to meet payment commitments, which was qualified by the CJEU as 'profiling'. More specifically, the system established 'a prognosis on the probability of a future behaviour of a person ('score'), such as the repayment of a loan, based on certain characteristics of that person. The establishment of scores ('scoring') is based on the assumption that, by assigning a person to a group of other persons with comparable characteristics who have behaved in a certain way, similar behaviour can be predicted. 114 According to the CJEU, this activity met the definition of 'profiling' within the meaning of Article 4(4) GDPR. 115 This form of profiling may also be considered to constitute an evaluation of persons based on their personal characteristics within the meaning of Article 5(1)(c) AI Act, which will be prohibited if done with AI systems and provided that the other conditions for the application of that provision are fulfilled.
## b) Over a certain period of time
(155) The prohibition in Article 5(1)(c) AI Act requires that the evaluation or classification is based  on  data  that  spans  over  ' a  certain  period  of  time' .  This  suggests  that  the assessment should not be limited to a one-time or an at once rating or grading with data or behaviour from a very specific individual context. At the same time, it is important that this condition is assessed, taking all circumstances of the case into account to avoid circumvention of the scope of the prohibition.
For example, an authority for migration and asylum implements a partly automated surveillance system at refugee camps built on a range of surveillance infrastructure, including cameras and motion sensors. If the analysed data spans a period of time and specific individuals are evaluated (such as migrants) for example to ascertain whether they are at risk of trying to abscond, then this would qualify as 'over a certain period of time' and the prohibition in Article 5(1)(c) AI Act may apply if all other conditions are fulfilled.
## c) Based on their social behaviour or known, inferred or predicted personal or personality characteristics
(156) The practices of 'evaluation' and 'classification' prohibited under Article 5(1)(c) AI Act must be based on the AI-enabled processing of data (often extensive) in relation to either i) the social behaviour of individuals or groups of persons or ii) their known, inferred or predicted personal and personality characteristics, or both. The data may be
113 Judgment of the Court of Justice of 7 December 2023, SCHUFA Holding (Scoring) , C-634/21, EU:C:2023:957 (hereinafter referred to as the ' SCHUFA I judgment') , e.g. paragraph 47.
114 Ibidem , paragraph 14 (own emphasis).
115 Ibidem , paragraph 47.
directly  provided  by  the  persons  or  indirectly  collected,  i.e.  through  surveillance, obtained from third parties or through inferences from other information.
