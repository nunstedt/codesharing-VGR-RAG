This  does  not  include  AI systems to the output of which natural persons are not directly exposed, such as tools used to organise, optimise or  structure  political  campaigns  from  an  administrative  or  logistical  point  of  view.
## Technical documentation referred to in Article 11(1)
The technical documentation referred to in Article 11(1) shall contain at least the following information, as applicable to the  relevant  AI  system:
- 1. A general  description of  the  AI  system  including:
- (a) its  intended purpose, the name of the provider and the version of the system reflecting its relation to previous versions;
- (b) how the AI system interacts with, or can be used to interact with, hardware or software, including with other AI systems,  that  are  not  part  of  the  AI  system  itself,  where  applicable;
- (c) the  versions  of  relevant  software  or  firmware,  and  any  requirements  related  to version  updates;
- (d) the  description  of  all  the  forms  in  which  the  AI  system  is  placed  on  the  market  or  put  into  service,  such  as software  packages embedded into hardware,  downloads, or  APIs;
- (e) the  description  of  the  hardware  on  which  the  AI  system  is  intended  to  run;
- (f) where  the  AI  system  is  a  component  of  products,  photographs  or  illustrations  showing  external  features,  the marking and internal layout of  those  products;
- (g) a  basic  description  of  the  user-interface  provided  to  the  deployer;
- (h) instructions for use for the deployer, and a basic description of the user-interface provided to the deployer, where applicable;
- 2. A detailed  description  of  the  elements  of  the  AI  system  and  of  the  process  for  its  development,  including:
- (a) the methods and steps performed for the development of the AI system, including, where relevant, recourse to pre-trained systems or  tools provided by third parties and how those were used, integrated or  modified by the provider;
- (b) the design specifications of the system, namely the general logic of the AI system and of the algorithms; the key design  choices  including  the  rationale  and  assumptions  made,  including  with  regard  to  persons  or  groups  of persons in respect of who, the system is intended to be used; the main classification choices; what the system is designed to optimise for, and the relevance of  the different parameters; the description of  the expected output and  output  quality  of  the  system;  the  decisions  about  any  possible  trade-off  made  regarding  the  technical solutions  adopted  to  comply  with  the  requirements  set  out  in  Chapter  III,  Section  2;
- (c) the description of the system architecture explaining how software components build on or feed into each other and integrate into the overall processing; the computational resources used to develop, train, test and validate the AI  system;
- (d) where  relevant,  the  data  requirements  in  terms  of  datasheets  describing  the  training  methodologies  and techniques and the training data sets used, including a general description of these data sets, information about their  provenance, scope and main characteristics; how the data was obtained and selected; labelling procedures (e.g.  for  supervised  learning),  data  cleaning  methodologies  (e.g.  outliers  detection);
- (e) assessment of the human oversight measures needed in accordance with Article 14, including an assessment of the  technical  measures  needed to facilitate the  interpretation  of  the  outputs  of AI  systems  by the  deployers, in accordance with Article 13(3),  point  (d);
- (f) where  applicable,  a  detailed  description  of  pre-determined  changes  to  the  AI  system  and  its  performance, together  with  all  the  relevant  information  related  to  the  technical  solutions  adopted  to  ensure  continuous compliance of  the  AI  system with  the  relevant  requirements  set  out  in  Chapter  III,  Section  2;
- (g) the validation and testing procedures used, including information about the validation and testing data used and their  main  characteristics;  metrics  used  to  measure  accuracy,  robustness  and  compliance  with  other  relevant requirements set out in Chapter III, Section 2, as well as potentially discriminatory impacts; test logs and all test reports dated and signed by the responsible persons, including with regard to pre-determined changes as referred to  under  point  (f);
- (h) cybersecurity  measures  put  in place;
- 3. Detailed information about the monitoring, functioning and control of the AI system, in particular  with regard to: its  capabilities  and  limitations  in  performance,  including  the  degrees  of  accuracy  for  specific  persons  or  groups  of persons  on  which  the  system  is  intended  to  be  used  and  the  overall  expected  level  of  accuracy  in  relation  to  its intended purpose; the foreseeable unintended outcomes and sources of risks to health and safety, fundamental rights and  discrimination  in  view  of  the  intended  purpose  of  the  AI  system;  the  human  oversight  measures  needed  in accordance  with  Article  14,  including  the  technical  measures  put  in  place  to  facilitate  the  interpretation  of  the outputs  of  AI  systems  by  the  deployers;  specifications  on  input  data,  as  appropriate;
- 4. A description of  the  appropriateness  of  the  performance  metrics  for  the  specific  AI  system;
- 5. A detailed  description  of  the  risk  management  system  in  accordance  with  Article  9;
- 6. A description of  relevant  changes made  by the  provider  to  the  system  through  its  lifecycle;
- 7. A  list  of  the  harmonised  standards  applied  in  full  or  in  part  the  references  of  which  have  been  published  in  the Official Journal of the European Union ;  where no such harmonised standards have been applied, a detailed description of the solutions adopted to meet the requirements set out in Chapter III, Section 2, including a list of other relevant standards  and  technical  specifications  applied;
- 8. A copy of  the  EU  declaration  of  conformity  referred  to  in  Article  47;
- 9. A  detailed  description  of  the  system  in  place  to  evaluate  the  AI  system  performance  in  the  post-market  phase  in accordance with Article 72,  including  the  post-market  monitoring  plan  referred  to  in  Article  72(3).
## ANNEX V
## EU declaration of conformity
The EU declaration of conformity referred to in Article  47,  shall  contain  all  of  the  following  information:
- 1. AI system name and type and any additional unambiguous reference allowing the identification and traceability of the  AI  system;
- 2. The name and address of  the  provider  or,  where  applicable,  of  their  authorised  representative;
- 3. A statement that the EU declaration of conformity referred to in Article 47 is issued under the sole responsibility of the  provider;
- 4. A  statement  that  the  AI  system  is  in  conformity  with  this  Regulation  and,  if  applicable,  with  any  other  relevant Union law that provides for  the  issuing  of  the  EU  declaration  of  conformity  referred  to  in  Article  47;
- 5. Where  an  AI  system  involves  the  processing  of  personal  data,  a  statement  that  that  AI  system  complies  with Regulations  (EU)  2016/679  and  (EU)  2018/1725  and  Directive  (EU)  2016/680;
- 6. References  to  any  relevant  harmonised  standards  used  or  any  other  common  specification  in  relation  to  which conformity is  declared;
- 7. Where  applicable,  the  name  and  identification  number  of  the  notified  body,  a  description  of  the  conformity assessment  procedure  performed, and  identification  of  the  certificate  issued;
- 8. The  place  and  date  of  issue  of  the  declaration,  the  name  and  function  of  the  person  who  signed  it,  as  well  as  an indication  for,  or  on  behalf of  whom,  that  person  signed,  a  signature.
## ANNEX VI
## Conformity assessment procedure based on internal control
- 1. The conformity assessment procedure based on internal control is the conformity assessment procedure based on points  2,  3  and  4.
- 2. The  provider  verifies  that  the  established  quality  management  system  is  in  compliance  with  the  requirements  of Article  17.
- 3. The provider examines the information contained in the technical documentation in order to assess the compliance of  the  AI  system  with  the  relevant  essential  requirements  set  out  in  Chapter  III,  Section  2.
- 4. The provider also verifies that the design and development process of the AI system and its post-market monitoring as  referred  to  in  Article  72  is  consistent  with  the  technical  documentation.
## Conformity based on an assessment of  the quality management system and an assessment of  the technical  documentation
- 1. Introduction
- Conformity  based  on  an  assessment  of  the  quality  management  system  and  an  assessment  of  the  technical documentation is the conformity assessment procedure based on points 2 to 5.
## 2. Overview
The  approved  quality  management  system  for  the  design,  development  and  testing  of  AI  systems  pursuant  to Article 17 shall be examined in accordance with point 3 and shall be subject to surveillance as specified in point 5. The technical documentation of  the  AI  system shall  be  examined  in  accordance  with  point  4.
## 3. Quality  management system
- . The application  of  the  provider  shall  include:
- (a) the name and address of the provider and, if the application is lodged by an authorised representative, also their name and address;
- (b) the  list  of  AI  systems  covered  under  the  same  quality  management  system;
- (c) the  technical  documentation  for  each  AI  system  covered  under  the  same  quality  management  system;
- (d) the  documentation  concerning  the  quality  management  system  which  shall  cover  all  the  aspects  listed  under Article  17;
- (e) a  description  of  the  procedures  in  place  to  ensure  that  the  quality  management  system  remains  adequate  and effective;
- (f) a  written  declaration  that  the  same  application  has  not  been  lodged  with  any other  notified  body.
- . The quality management system shall be assessed by the notified body, which shall determine whether it satisfies the requirements  referred  to  in  Article  17.
- The decision  shall  be  notified  to  the  provider  or  its  authorised  representative.
- The notification shall contain the conclusions of the assessment of the quality management system and the reasoned assessment  decision.
- . 