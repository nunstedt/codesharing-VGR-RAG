208 However,  the  concept  of  'a genuine and present or genuine and foreseeable threat', as used in Article 5(1)(h)(ii), is an autonomous notion of Union law and should therefore be assessed, in principle, independently of national definitions. The threat relates not to terrorism in general, but specifically to a threat of a terrorist attack.
Characteristics of the threat: genuine and present or genuine and foreseeable
(347) The threshold of seriousness that a threat needs to reach to allow for the use of realtime  RBI  systems  in  publicly  accessible  spaces  for  law  enforcement  purposes  was
204 Recital 37 of Regulation 2023/1543.
205 https://www.government.nl/topics/counterterrorism-and-national-security/risk-of-an-attack-threat-level 206 https://cuta.belgium.be
https://crisiscenter.be/en/risks-belgium/security-risks/terrorism-and-extremism
207 https://www.sgdsn.gouv.fr/vigipirate#
https://www.sgdsn.gouv.fr/files/files/Vigipirate/20160130-np-sgdsn-pse-tackling-terrorism-together.pdf 208 https://www.krisinformation.se/en/hazards-and-risks/terrorism
inspired by the CJEU's case law on data retention and passenger name record measures aimed  at  safeguarding  national  security,  in particular, against terrorist attacks. According to the CJEU, in those contexts, 'a threat to national security must be genuine and  present,  or  at  the  very  least,  foreseeable,  which  presupposes  that  sufficiently concrete circumstances have arisen.' 209
## Prevention
(348) Contrary to Article 5(1)(h)(i) and Article 5(1)(h)(iii) AI Act, the scenario described in Article 5(1)(h)(ii) does not specify that the use of real-time RBI is permitted to locate or  identify  a  concrete  person.  Its  purpose  is  the  prevention  of  a  particular  threat. Accordingly, the scenario may also cover the use of real-time RBI to detect and follow 'terrorists  on  the  move',  i.e.  several  persons  linked  to  the  same  threat,  if  there  are concrete indications that those persons plan to commit a terrorist attack, but it is not clear where.
Real-time RBI to prevent a terrorist attack in a park
The police are informed that a person is running around a park looking for people to attack with a knife while he is screaming violent extremist slogans usually linked to terrorist attacks and terrorist groups.  If the Member State has authorised the use of real-time RBI  in  the scenario described  by  Article 5(1)(h)(ii) AI  Act,  law enforcement authorities may use real-time RBI to identify and locate the person in and around the park to prevent the attack, provided the other conditions of Article 5(2)-(7) AI Act have been met.
## . Localisation  and  identification  of  suspects  of  certain  crimes
(349) Article 5(1)(h)(iii) AI Act allows the real-time use of RBI in publicly accessible spaces for  'the  localisation  and  identification  of  a  person  suspected  of  having  committed a criminal offence, for the purpose of conducting a criminal investigation or prosecution or executing a criminal penalty for offences referred to in Annex II and punishable in the  Member  States  concerned  by  a  custodial  sentence  or  a  detention  order  for  a maximum period of at least four years.'
Annex II AI Act provides an exhaustive list of serious crimes for which the use of realtime RBI may be authorised for the aforementioned objective. Those criminal offences are:
- - terrorism,
- - trafficking in human beings,
209 Judgment of the Court of Justice of 20 September 2022, SpaceNet , C-793/19 (Joined Cases C-793/19, C-794/19), ECLI:EU:C:2022:702, paragraph 93.
- - sexual exploitation of children, and child pornography,
- - illicit trafficking in narcotic drugs or psychotropic substances,
- - illicit trafficking in weapons, munitions or explosives,
- - murder, grievous bodily injury,
- - illicit trade in human organs or tissue,
- - illicit trafficking in nuclear or radioactive materials,
- - kidnapping, illegal restraint or hostage-taking,
- - crimes within the jurisdiction of the International Criminal Court,
- - unlawful seizure of aircraft or ships,
- - rape,
- - environmental crime,
- - organised or armed robbery,
- - sabotage,
- - participation in a criminal organisation involved in one or more of the offences listed above.
## a) Localisation and identification
(350) A Member State may authorise the use of real-time RBI in publicly accessible spaces for law enforcement purposes to locate and identify a suspect of a criminal offence to conduct  a  criminal  investigation,  prosecute  that  person  for  the  crime  committed,  or execute an existing sentence.
## b) Suspects and Perpetrators
(351) Article 5(1)(h)(iii) AI  Act  covers  two  categories of individuals:  suspects  and perpetrators. A suspect is a person with regard to whom there are serious grounds for believing that they have committed a criminal offence, and sufficient evidence of that person's involvement in the offence has already been gathered. A perpetrator is a person who  is  accused  or  convicted  of  having  committed  a  criminal  offence.  The  same conditions (crime listed in Annex II and maximum punishment of at least 4 years) apply to locate or identify the accomplice of the crimes listed in Annex II AI Act.
## c) List of serious crimes
(352) Only serious  crimes  justify  the  use  of  real-time  RBI  systems  in  publicly  accessible spaces for law enforcement purposes.
(353) The first five offences listed in Annex II AI Act are the same as the 'euro crimes; listed in Article 83 TFEU, while the other offences constitute priorities for law enforcement
cooperation. 210 Some  of  them  (e.g.  kidnapping,  illicit  trafficking  in  nuclear  or radioactive materials) may be linked to terrorism. 211
(354) Although all the  criminal offences listed  in  Annex  II  may  trigger  the  issuance  of  a European Arrest Warrant ('EAW') against a suspect or perpetrator, the use of real-time RBI to locate and identify a suspect for one of these serious criminal offences does not require that an EAW has been issued.
(355) Moreover, to use real-time RBI for this purpose, the respective criminal offence must be punishable in the Member State concerned by a custodial sentence or a detention order for a maximum period of at least four years.
During  a  busy  festival  in  a  city,  police  authorities  deploy  live  facial  recognition technologies to monitor the area around the festival and identify wanted individuals with outstanding arrest warrants for illegal drug trafficking and sexual offences. At different entrances to the festival, the police use live video footage of people passing in front of a mobile camera to compare their faces with a watchlist of faces of wanted individuals.
First,  concerning  the  offence  types,  RBI  can  be  used  in  case  of  illegal  drug trafficking. However sexual offences are not on the list of offences, unless they relate to the sexual exploitation of children, child sexual abuse material, or rape. The police are  not  allowed  to  deploy  real-time  facial  recognition  technologies  in  a  broad, untargeted manner, i.e. in the hope of finding wanted criminals and taking them off the streets.
The  case  is  different  if  the  police  have  received  a  physical  description  with  a photograph of a wanted individual that is subject to a European Arrest Warrant for drug trafficking and they have reasons to believe that he will be present at the festival. In  those  circumstances,  deploying  real-time  facial  recognition  technologies  to identify a targeted individual may be covered by Article 5(1)(h)(iii) AI Act.
After a serious terror attack at a Christmas market with 12 deaths, the police uses real-time facial recognition technologies to identify the offender and to see to where he  is  escaping.  In  that  context  they  also  use  the  real-time  facial  recognition technologies of the nearby train station and at destination stations of the trains leaving from there shortly after the attack. In the case of a terror attack, such use can be permitted under Article 5(1)(h)(iii) AI Act.
(356) A link between Article 5(1)(h)(i) and Article 5(1)(h)(iii) AI Act may be made for the crimes covered by the scenario described in Article 5(1)(h)(i) AI Act. While real-time RBI systems may be deployed to find a victim or a missing person, those systems may
210 Europol priorities.
211 See Recital 33 and see definition of terrorist offences in Article 3 of Directive 2017/541.
also be used to locate and identify the perpetrator or suspect of trafficking in human beings, sexual exploitation as far as it concerns children (as listed in Annex II), and kidnapping (as far as the abduction mentioned in Article 5(1)(h)(i) AI Act qualifies as kidnapping as listed in Annex II AI Act). A link may also be made between Article 5(1)(h)(ii) and (iii) AI Act: real-time RBI systems may be used to prevent a threat falling within the scope of Article 5(1)(h)(ii)  and, if that threat materialises, those systems may be used to identify/locate the perpetrator ' on the move'.
## 10. SAFEGUARDS AND CONDITIONS FOR THE EXCEPTIONS (ARTICLE 5(2)(7) AI ACT)
## . Targeted individual and safeguards (Article 5(2) AI Act)
## Article 5(2) AI Act provides:
- 'The use of 'real-time' remote biometric identification systems in publicly accessible spaces for the purposes of law enforcement for any of the objectives referred to in paragraph 1, first subparagraph, point (h), shall be deployed for the purposes set out in that point only to confirm the identity of the specifically targeted individual, and it shall take into account the following elements:
- (a) the nature of the situation giving rise to the possible use, in particular the seriousness, probability and scale of the harm that would be caused if the system were not used;
- (b) the consequences of the use of the system for the rights and freedoms of all persons concerned, in particular the seriousness, probability and scale of those consequences.
In addition, the use of 'real-time' remote biometric identification systems in publicly accessible  spaces  for  the  purposes  of  law  enforcement  for  any  of  the  objectives referred to in paragraph 1, first subparagraph, point (h), of this Article shall comply with necessary and proportionate safeguards and conditions in relation to the use in accordance with the national law authorising the use thereof, in particular as regards the temporal, geographic and personal limitations. The use of the 'real-time' remote biometric identification system in publicly accessible spaces shall be authorised only if  the  law  enforcement  authority  has  completed  a fundamental  rights  impact assessment as provided for in Article 27 and has registered the system in the EU database according to Article 49. However, in duly justified cases of urgency, the use of  such  systems  may be commenced without the registration in the EU  database, provided that such registration is completed without undue delay.'
(357) The use of real-time RBI systems for one of the objectives listed in Article 5(1)(h)(i) to (iii) AI Act is subject to certain safeguards and conditions, which are detailed in Article 5(2) to Article 5(7) AI Act.
(358) First,  the  use  of  real-time  RBI  systems  in  publicly  accessible  spaces  for  law enforcement  purposes  is  only  allowed to  'confirm  the  identity  of  the  specifically
targeted individual'. This first condition aims to balance the seriousness of the situation and the harm resulting from not using the system with the impact of the technology on individuals' rights and freedoms. It aims to avoid mass surveillance by targeting an individual for the deployment of real-time RBI. As a consequence, the deployment of a  real-time  RBI  system  in  publicly  accessible  spaces  for  law  enforcement  purposes should only be authorized for targeted individuals.
(359) The use of the expression 'confirming the identity', as opposed to 'identification', is meant  as  an  additional  safeguard  for  the  fundamental  rights  limiting  the  risk  of indiscriminate surveillance and implies that the identification of an individual within the  meaning of Article  5(1)(h)  AI  Act  must  be  targeted.  That  expression  should  be understood as meaning that the use of real-time RBI may only be initiated to search for specific individuals for which the law enforcement authorities have reasons to believe or are informed that they are victims of the crimes listed in Article 5(1)(h)(i) AI Act or are involved in one of the scenarios described in Article 5(1)(h)(ii) or Article 5(1)(h)(iii) AI Act. This means, in practice, a comparison of the data collected real-time with the data contained in the reference database. As regards the use of real-time RBI system in the  scenarios  described  in  Article  5(1)(h)(ii)  AI  Act  and  for  conducting  a  criminal investigation within the meaning of 5(1)(h)(iii) AI Act, law enforcement authorities do not necessarily need to know the identity of the individuals they are searching for before using  the  system.  If  they  have  factual  indications  and  information  about  a  planned terrorist attack by a terrorist group (without knowing who will execute the plan) at a specific time and place, the RBI system may be used to identify the offender from the terrorist group, provided the law enforcement authorities have constituted a reference database containing the biometric data of the individuals forming part of the terrorist group. In all three scenarios described in Article 5(1)(h)(i) to (iii) AI Act, 'confirming the identity' may also include the localisation of the person in question.
(360) Second, before using the system, the nature of the situation giving rise to the possible use, in particular, the seriousness, probability and scale of the harm for natural persons, society and law enforcement purposes that would be caused if the system were not used, should be assessed against the consequences of the use of the system on the rights and freedoms of the persons concerned, in particular, the seriousness, probability and scale of those consequences. This should include evaluating whether less intrusive alternative solutions  are  available  to  the  law  enforcement  authorities  or  entities  acting  on  their behalf.
For example, law enforcement authorities are prohibited from using real-time facial recognition systems in the street based on general security, crime prevention and overcrowding concerns, since that would involve the constant monitoring and surveillance of all persons, it is not limited in time, and it would therefore not meet the criteria for the exception from the prohibition laid down in Article 5(1)(h) AI Act.
- (361) The  ' seriousness '  criterion,  applied  here  in  connection  to  the  possible  harm  and consequences, implies a variation in degrees of interference with the fundamental rights at  stake,  which  is  linked  to  the  principle  of  proportionality. 212 Concerning  the interferences with fundamental rights, some interferences are viewed as more serious than others.
- (362) The  ' scale '  criterion  refers,  in  particular,  to  the  number  and  categories  of  persons affected  by  the  interference  (including  children  and  vulnerable  or  marginalised persons).
- (363) Finally, the ' probability ' is the likelihood that an event will occur.
- (364) The assessment of the seriousness, scale and probability of the harm and consequences should  all  be  part  of  the  Fundamental  Rights  Impact  Assessment  that  the  law enforcement  authority  is  obliged  to  complete  (see  below) . That  assessment  will  be concluded on a case-by-case basis.
- (365) Third, the real-time use of RBI should be clearly limited in terms of geographic scope, duration, and the targeted person. This is to ensure that the RBI system is only used when strictly necessary.
- (366) Concerning the geographic restriction , it may cover one or several geographical areas based  on  'objective and  non-discriminatory  factors'. In the case of  biometric identification this implies that the geographic restriction applies to a clearly delineated boundary  for  which  there  are  indications  that  the  event  will  take  place.  Such  a delineation should -under normal circumstances- not comprise an entire city or country, but should be more targeted.
- (367) Another  safeguard  relates  to  the personal  scope of  the  measure,  i.e.  defining  the categories of persons concerned. This would exclude the untargeted, indiscriminate identification of persons, without further indications of an incident.
- (368) Finally, the time limit is a period limited to what is strictly necessary, but which may be extended in case of need in accordance with the applicable rules. The use of realtime RBI systems therefore cannot be for an indefinite or vague period of time. The period needs to be determined in light of the concrete indications that lead to the use of RBI systems.
- (369) Fourth, before deployment, the law enforcement authority deploying the real-time RBI system  must  have  conducted  a  Fundamental  Right  Impact  Assessment  (FRIA)  and registered the system in the EU database (except in a duly justified case).
## . Fundamental Rights Impact Assessment
212 Judgment of the Court of Justice of 2 October 2018, Ministerio Fiscal , C-207/16, ECLI:EU:C:2018:788, paragraph 55, where the Court states that 'access must be proportionate to the seriousness of the interference with the fundamental rights in question'.
(370) FRIAs carried out in application of Article 5(2) AI Act must comply with the conditions laid down in Article 27 AI Act. That provision sets out the requirements concerning FRIAs applicable to high-risk AI systems.
(371) In the period between when the prohibitions in Article 5 AI Act become applicable (after 2 February 2025) but the provisions on high-risk AI systems are not yet applicable (before 2 August 2026), the requirements for FRIA set out in Article 27 AI Act should be implemented by the deployers of real-time RBI systems meeting the conditions to benefit from one or more of the exceptions in Article 5(1)(h) AI Act. The following provisional guidance relates only to the use of  real-time RBI in publicly accessible spaces for law enforcement purposes for the period before the obligations for high-risk AI systems become applicable and the Commission adopts the template for FRIA and provides further guidance on the obligation under Article 27 AI Act.
(372) A FRIA is a new type of impact assessment that aims to identify the impact that certain high-risk AI systems, including RBI systems, may produce on fundamental rights. A FRIA is an accountability tool. The FRIA does not replace the existing Data Protection Impact  Assessment  (DPIA)  that  data  controllers  (i.e.  those  responsible  for  the processing of personal data) must perform under Article 27 LED, Article 35 GDPR or Article 39 EUDPR.
For example, a DPIA must be conducted when biometric data are processed through new technologies likely to result in a high risk to the rights and freedoms of natural persons (such as CCTV, AI facial recognition, and body-worn cameras) in publicly accessible spaces.
(373) Whereas a DPIA focuses on the risks to the rights and freedoms of individuals resulting from the processing of their personal data, a FRIA covers the possible impact of AI systems on individuals' fundamental rights more generally. The scope of a FRIA is therefore broader in terms of activities covered and fundamental rights assessed. Where personal data are processed by the AI system (which is the case of RBI systems), the FRIA should complement the DPIA performed by the deployer as data controller, 213 without covering aspects already addressed in the DPIA and avoiding overlaps. The analysis of the FRIA in these Guidelines is limited to the authorized use of RBI in realtime and is aimed to serve as a preliminary guidance for deployers in this interim period before the AI Office provides a template. 214
(374) The  obligation  to  carry  out  the  FRIA  under  Article  5(2)  AI  Act  is  imposed  on  the deployers of the RBI system, and not entities or bodies or anyone else acting on their behalf.  If  other  actors  are  acting  on  behalf  of  the  deployer/the  law  enforcement authority, they will have to contribute to the preparation of the FRIA with all relevant information to ensure it is properly carried out.
213 Article 27(4) AI Act.
214 Thus, the analysis does not cover the case of high-risk AI systems in general.
(375) A FRIA must be carried out before the deployment of the authorized real-time RBI system.
(376) According to Article 27 AI Act, a FRIA should include the following information:
- · A description of the RBI use and the deployer's processes for the use, together with the intended purpose of use:
The description should include:
- - the name of the deployer;
- - the law enforcement purpose(s) for which the real-time RBI system will be used;
- - the description of the reference database against which the biometric identification will be compared, including the sources of the biometric data (facial images, voice samples, etc.) that will be used;
- - the description of the technology underlying the system to explain its functioning (by referencing the available documentation provided by the provider and its name) 215 ;
- - the legal basis on which the real-time RBI will be deployed.
- · The period of use and frequency of use
Each individual use of a real-time RBI system for one of the permitted exceptions must be  authorised  prior  to  its  deployment  by  a  judicial  authority  or  other  independent authority under Article 5(3) AI Act. By contrast, for the FRIA, deployers must provide a general indication of the intended period of use and the expected frequency.
- · The categories of persons and groups affected by the system
For the purpose of the exception in Article 5(1)(h) AI Act, the FRIA should distinguish between:
- - The targeted individual, who may be a victim of a crime, a perpetrator, or a suspect,
- - The individuals whose biometric data are included in the reference database, and
- - Categories of persons who are present in the surrounding areas where the RBI system will be deployed.
The use of real-time RBI systems will not only affect the fundamental rights of the targeted individual. The rights of other individuals whose biometric data are used for comparison purposes, passersby, and people incidentally presented in the search area will  also  be  affected.  The  description  of  the  geographic  scope  of  the  search  area(s) covered by the real-time RBI system will impact the number of persons affected by the system.
215 Once the rules on high-risk AI system enter into force, this can be done by reference the registration number of the system in the EU database and the available information for the system contained therein.
- · The specific risks of harm to the affected persons:
(377) The fundamental rights that may be affected by the use of real-time RBI in publicly accessible spaces for law enforcement purposes include, in particular:
- -the right to private and family life, including people's reasonable expectation of anonymity in public spaces;
- -the right to data protection, as RBI systems rely on the processing of biometric data and other personal data (e.g. names, ID numbers, as well as sensitive data such as ethnicity) to identify specific individuals;
- -freedom of thought, conscience and religion, freedom of expression and freedom of assembly and association in the public spaces being searched, on which the use of RBI systems could have a chilling effect, preventing individuals to fully exercise their rights and freedoms, since if individuals know that they are monitored, they might change their behaviour, or even prevent themselves to behave in a certain manner;
- -the right to an effective remedy and a fair trial;
- -the right to non-discrimination if the system embeds biases (such as gender, ethnic or racial biases) and leads to the misidentification of a suspect or perpetrator;
- -the right to human dignity by the feeling of being reduced to an object of the system;
- -the  presumption  of  innocence  and  right  to  defence;  since  no  decision  adversely affecting  an  individual  may  be  solely  taken  on  the  output  of  the  real-time  RBI system.
- -the rights of the child in case the victim, missing person or suspect is a minor;
- -the rights of the elderly in the case of a missing person.
To assess the specific risks of harm likely to impact the identified affected person(s) or group(s), the FRIA must identify the fundamental rights of those persons and assess the impact on their fundamental rights, including the severity of the impact and its scale, taking into account the potentially affected persons.
This part of the FRIA should also include the assessment of whether the use of a realtime  RBI  system  is  necessary  and  proportionate  considering  the  objectives  and  the circumstances in which its use is intended, including the existence or absence of less intrusive alternatives. The FRIA should describe the performance and accuracy level of the system, based on the technical documentation and, if available, the training data on which the technology was tested and developed to prevent biases and discrimination.
The FRIA should also identify the impact of use of a real-time RBI system on the fundamental rights of all individuals potentially affected, in particular the suspect or perpetrator, the victim searched and other individuals present in the publicly accessible spaces subject to the search. To the extent that the system processes the biometric data of these individuals, their rights to private and family life and data protection will be impacted, which will be assessed as part of the DPIA as far as the data processing
activities  are  concerned.  For  other  activities  related  to  the  use  of  the  real-time  RBI systems and the impact on other fundamental rights, the FRIA will complement the DPIA.  Depending  on  the  context  of  deployment,  other  fundamental  rights  of  these individuals, such as their rights to human dignity, freedom of thought, conscience and religion, assembly or freedom of expression, rights to an effective remedy and a fair trial,  presumption  of  innocence  and  right  of  defence,  rights  of  the  child,  may  be impacted.
The assessment under the FRIA should be performed at an abstract level, prior to the first putting into service of the AI system. Specific context-dependent considerations that determine the impact of use in each individual case where a real-time RBI system is  used  should  be  further  elaborated  in  the  individual  request  for  requesting  the authorisation by a judicial authority or other independent administrative authority of each use of the RBI system (see section . below).
## · Human oversight measures
According to Article 5(3) AI Act, no decision that would adversely affect an individual may  be  taken  solely  on  the  basis  of  the  output  of  the  real-time  RBI  system.  As  a consequence, the FRIA should describe the procedures that will be followed during the operation of the system and how the output will be interpreted in the context of decisionmaking process. The procedures should provide instructions on the deployment of the RBI system, clarify the role of a human agent in verifying and interpreting the output and provide training to operate the system. The person in charge of human oversight should have sufficient 'AI literacy, training and authority' 216 to  understand how the system functions and when it underperforms or malfunctions.
Other considerations for human oversight and monitoring under Articles 14 and 26 AI Act are also relevant and should be described.
## · Risk mitigation measures
Beyond implementing human oversight measures (including to avoid discriminatory measures), the deployer should explain redress measures in case a risk materialises, including the governance procedures and the complaint mechanisms (such as in the case of a misidentification).
## . Registration of the authorized RBI systems
(378) Article 5(2) AI Act also obliges the deployer of a real-time RBI system used in publicly accessible  spaces  for  law  enforcement  purposes  to  register  the  system  in  the  EU database  provided  for  in  Article  49  AI  Act.  However,  in  cases  of  a  duly  justified emergency  (such  as  an  imminent  threat),  deployment  may  start  even  prior  to registration, provided the law enforcement authority registers the system without undue delay. Undue delay should be understood as meaning 'as soon as possible' considering
216 Recital 91 AI Act.
the circumstances of the emergency that prevented the registration of the system prior to its use. Whether registration meets that criterion requires an appreciation on a caseby-case basis. It cannot be defined a priori with a precise time limit. The delay should not be caused by a deliberate action. According to Article 49(4) AI Act, RBI systems used  for  the  purpose  of  law  enforcement  will  be  registered  in  a  secure  non-public section of the database, with limited information and limited access to that information.
For  example,  requesting  law  enforcement  authorities  to  register  the  RBI  system within 24 hours of the use might be considered a reasonable delay where the system was deployed in a situation of an imminent threat to life, such as in the scenario of a live shooter.
## . Need for prior authorisation
(379) Article 5(3) AI Act requires prior authorisation of each individual use of a real-time RBI system and prohibits automated decision-making based solely on the output of such a system which produces an adverse legal effect.
## Article 5(3) AI Act provides:
For the purposes of paragraph 1, first subparagraph, point (h) and paragraph 2, each use  for  the  purposes  of  law  enforcement  of  a  'real-time'  remote  biometric identification  system  in  publicly  accessible  spaces  shall  be  subject  to  a  prior authorisation  granted  by  a  judicial  authority  or  an  independent  administrative authority whose decision is binding of the Member State in which the use is to take place, issued upon a reasoned request and in accordance with the detailed rules of national  law  referred  to  in  paragraph  5.  However,  in  a  duly  justified  situation  of urgency,  the  use  of  such  system  may  be  commenced  without  an  authorisation provided that such authorisation is requested without undue delay, at the latest within 24 hours. If such authorisation is rejected, the use shall be stopped with immediate effect  and  all  the  data,  as  well  as  the  results  and  outputs  of  that  use  shall  be immediately discarded and deleted.
The competent judicial authority or an independent administrative authority whose decision is binding shall grant the authorisation only where it is satisfied, on the basis of objective evidence or clear indications presented to it, that the use of the 'realtime'  remote  biometric  identification  system  concerned  is  necessary  for,  and proportionate  to,  achieving  one  of  the  objectives  specified  in  paragraph  1,  first subparagraph, point (h), as identified in the request and, in particular, remains limited to what is strictly necessary concerning the period of time as well as the geographic and personal scope. In deciding on the request, that authority shall take into account the elements referred to in paragraph 2. No decision that produces an adverse legal effect on a person may be taken based solely on the output of the 'real-time' remote biometric identification system.
- (380) The objective for requiring prior authorisation ('authorisation ex ante') for any use of a 'real-time' RBI system in publicly accessible spaces for law enforcement purposes is the need for an assessment and a decision as to whether any envisaged use of such a system for such purposes is:
- -    necessary  and proportionate to achieve any one of the objectives listed in Article 5(1)(h)(i)  to  (iii),  i.e.,  for  the  targeted  search  of  specific  victims,  the  prevention  of specific threats, or the localisation or identification of offenders;
and
- -  limited to what is strictly necessary concerning the time period and the geographic and personal scope.
- (381) The consequence of these requirements is that a double necessity and proportionality assessment  should  occur  prior  to  the  deployment  of  any  real-time  RBI  system  in publicly accessible spaces for law enforcement purposes. First, an assessment should be made by the user when performing a FRIA, as required by Article 5(2) AI Act. Second, in accordance with Article 5(3) AI Act, a judicial or independent administrative authority  must  also  assess  the  necessity  and  proportionality  of  using  such  a  system within the limits of the national law providing the legal basis for any such use, taking the Charter and other Union law into consideration. As a consequence, any such system may only be used 1) after a FRIA and 2) when the competent national authority has authorised such use.
(382) Article 5(3) AI Act must be read and understood in conjunction with Article 5(5) AI Act: for the use of a real-time RBI system to be authorized, a national law adopted in the Member States concerned must exist authorising such use. 217 Certain Member States already have a system of prior authorisation in place for the use of biometric systems under other Union or national law, such as data protection law.
## . The main principle: Prior authorisation by a judicial authority or an independent administrative authority
- (383) The use of real-time RBI systems which pursue one of the objectives listed in Article 5(1)(h)(i) to (iii) AI Act and which has been provided for in the national law of the Member States concerned must be authorized by a judicial authority or an independent administrative authority prior to its use . This is the main principle.
(384) However, there is an exception in the case of urgency. This shall be duly justified 218 . Urgency is  described as 'situations where the need to use the systems concerned is such as to make it effectively and objectively impossible to obtain an authorisation before commencing the use of the AI system' 219 In such case of urgency, 'the use of the  AI  system should be restricted to the absolute minimum necessary and  should  be
217 See also Article 5(2) AI Act: '(… ) in accordance with the national law authorising the use thereof. (…)'.
