Publicly accessible spaces should not include prisons or border control. Some other spaces may comprise both publicly accessible and non-publicly accessible spaces, such as the hallway of a private residential building necessary to access a doctor's office or an airport. Online spaces are not covered,  as  they  are  not  physical  spaces.  Whether  a  given  space  is  accessible  to  the  public  should  however  be determined on a case-by-case  basis,  having regard to the  specificities  of  the  individual  situation  at  hand.
- (20) In order to obtain the greatest benefits from AI systems while protecting fundamental rights, health and safety and to enable  democratic  control,  AI  literacy  should  equip  providers,  deployers  and  affected  persons  with  the  necessary notions  to  make  informed  decisions  regarding  AI  systems.  Those  notions  may  vary  with  regard  to  the  relevant context  and  can  include  understanding  the  correct  application  of  technical  elements  during  the  AI  system's development phase, the measures to be applied during its use, the suitable ways in which to interpret the AI system's output, and,  in  the  case  of  affected  persons,  the  knowledge  necessary  to  understand  how decisions  taken with  the assistance  of  AI  will  have  an  impact  on  them.  In  the  context of  the  application  this  Regulation,  AI  literacy  should provide all relevant actors in the AI value chain with the insights required to ensure the appropriate compliance and its  correct  enforcement.  Furthermore,  the  wide  implementation  of  AI  literacy  measures  and  the  introduction  of appropriate  follow-up  actions  could  contribute  to  improving  working  conditions  and  ultimately  sustain  the consolidation, and innovation path of trustworthy AI in the Union. The European Artificial Intelligence Board (the 'Board')  should  support  the  Commission,  to promote  AI  literacy  tools,  public  awareness  and  understanding  of  the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems. In cooperation with the relevant stakeholders, the Commission and the Member States should facilitate the drawing up of voluntary codes of conduct to  advance  AI  literacy  among  persons  dealing  with  the  development,  operation  and  use  of  AI.
- (21) In  order  to ensure  a  level  playing  field  and  an  effective  protection  of  rights  and  freedoms  of  individuals  across  the Union,  the  rules  established  by  this  Regulation  should  apply  to  providers  of  AI  systems  in  a  non-discriminatory manner, irrespective of whether they are established within the Union or in a third country, and to deployers of AI systems  established  within  the  Union.
- (22) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are not placed on the market, put into service, or  used in the Union. This is the case, for example, where an operator established  in  the  Union  contracts  certain  services  to  an  operator  established  in  a  third  country  in  relation  to  an activity to be performed by an AI system that would qualify as high-risk. In those circumstances, the AI system used in  a  third  country  by  the  operator  could  process  data  lawfully  collected  in  and  transferred  from  the  Union,  and provide  to  the  contracting  operator  in  the  Union  the  output  of  that  AI  system  resulting  from  that  processing, without  that  AI  system  being  placed  on  the  market,  put  into  service  or  used  in  the  Union.  To  prevent  the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and deployers of AI systems that are established in a third country, to the extent the output produced by those systems is intended to be used in the Union. Nonetheless, to take into account existing arrangements and special needs for  future cooperation with foreign partners with whom information and evidence  is  exchanged,  this  Regulation  should  not  apply  to  public  authorities  of  a  third  country  and  international organisations  when  acting  in  the  framework  of  cooperation  or  international  agreements  concluded  at  Union  or national level for law enforcement and judicial cooperation with the Union or the Member States, provided that the relevant third country or  international organisation provides adequate safeguards with respect to the protection of fundamental rights and freedoms of individuals. Where relevant, this may cover activities of entities entrusted by the third  countries  to  carry  out  specific  tasks  in  support  of  such  law  enforcement  and  judicial  cooperation.  Such framework  for  cooperation  or  agreements  have  been  established  bilaterally  between  Member  States  and  third countries or between the European Union, Europol and other Union agencies and third countries and international organisations. The authorities competent for supervision of the law enforcement and judicial authorities under this Regulation should assess whether  those frameworks  for cooperation or  international agreements include adequate safeguards  with  respect  to  the  protection  of  fundamental  rights  and  freedoms  of  individuals.  Recipient  national
authorities  and  Union  institutions,  bodies,  offices  and  agencies  making  use  of  such  outputs  in  the  Union  remain accountable to ensure their use complies with Union law. When those international agreements are revised or new ones are concluded in the future, the contracting parties should make utmost efforts to align those agreements with the  requirements  of  this  Regulation.
- (23) This Regulation should also apply to Union institutions, bodies, offices and agencies when acting as a provider or deployer  of  an  AI  system.
- (24) If, and insofar as, AI systems are placed on the market, put into service, or used with or without modification of such systems  for  military,  defence  or  national  security  purposes,  those  should  be  excluded  from  the  scope  of  this Regulation regardless of which type of entity is carrying out those activities, such as whether it is a public or private entity.  As  regards  military  and  defence  purposes,  such  exclusion  is  justified  both  by  Article  4(2)  TEU  and  by  the specificities of the Member States' and the common Union defence policy covered by Chapter 2 of Title V TEU that are subject to public international law, which is therefore the more appropriate legal framework for the regulation of AI  systems  in  the  context  of  the  use  of  lethal  force  and  other  AI  systems  in  the  context  of  military  and  defence activities.  As  regards  national  security  purposes,  the  exclusion  is  justified  both  by  the  fact  that  national  security remains the sole responsibility of Member States in accordance with Article 4(2) TEU and by the specific nature and operational needs of national security activities and specific national rules applicable to those activities. Nonetheless, if  an  AI  system developed, placed on the market, put into service or  used for  military, defence or  national security purposes is used outside those temporarily or permanently for other purposes, for example, civilian or humanitarian purposes, law enforcement or public security purposes, such a system would fall within the scope of this Regulation. In  that  case,  the  entity  using  the  AI  system  for  other  than  military,  defence  or  national  security  purposes  should ensure  the  compliance  of  the  AI  system  with  this  Regulation,  unless  the  system  is  already  compliant  with  this Regulation. AI systems placed on the market or put into service for an excluded purpose, namely military, defence or national security, and one or more non-excluded purposes, such as civilian purposes or law enforcement, fall within the scope of this Regulation and providers of those systems should ensure compliance with this Regulation. In those cases,  the  fact  that  an  AI  system  may  fall  within  the  scope  of  this  Regulation  should  not  affect  the  possibility  of entities  carrying  out  national  security,  defence  and  military  activities,  regardless  of  the  type  of  entity  carrying  out those activities, to use AI systems for national security, military and defence purposes, the use of which is excluded from  the  scope  of  this  Regulation.  An  AI  system  placed  on  the  market  for  civilian  or  law  enforcement  purposes which is used with or without modification for military, defence or national security purposes should not fall within the  scope  of  this  Regulation,  regardless  of  the  type  of  entity  carrying  out  those  activities.
- (25) This Regulation should support innovation, should respect freedom of science, and should not undermine research and  development  activity.  It  is  therefore  necessary  to  exclude  from  its  scope  AI  systems  and  models  specifically developed and put into service for the sole purpose of scientific research and development. Moreover, it is necessary to ensure that this Regulation does not otherwise affect scientific research and development activity on AI systems or models prior  to being  placed  on  the  market or  put  into service.  As  regards  product-oriented  research, testing and development activity regarding AI systems or models, the provisions of this Regulation should also not apply prior to those systems and models being put into service or placed on the market. That exclusion is without prejudice to the obligation to comply with this Regulation where an AI system falling into the scope of this Regulation is placed on  the  market  or  put  into  service  as  a  result  of  such  research  and  development  activity  and  to  the  application  of provisions on AI regulatory sandboxes and testing in real world conditions. Furthermore, without prejudice to the exclusion  of  AI  systems  specifically  developed  and  put  into  service  for  the  sole  purpose  of  scientific  research  and development, any other AI system that may be used for the conduct of any research and development activity should remain subject to the provisions of this Regulation. In any event, any research and development activity should be carried  out  in  accordance  with  recognised  ethical  and  professional  standards  for  scientific  research  and  should  be conducted in accordance with applicable Union law.
- (26) In  order  to introduce a proportionate and effective set of binding rules for AI systems, a clearly defined  risk-based approach should be followed. That approach should tailor  the type and content of such rules to the intensity and scope of the risks that AI systems can generate. It is therefore necessary to prohibit certain unacceptable AI practices, to  lay  down  requirements  for  high-risk  AI  systems  and  obligations  for  the  relevant  operators,  and  to  lay  down transparency obligations for  certain  AI  systems.
- (27) While the risk-based approach is the basis for a proportionate and effective set of binding rules, it is important to recall  the  2019  Ethics  guidelines  for  trustworthy  AI  developed  by  the  independent  AI  HLEG  appointed  by  the Commission.  In  those  guidelines,  the  AI  HLEG  developed  seven  non-binding  ethical  principles  for  AI  which  are intended to help ensure that AI is trustworthy and ethically sound. The seven principles include human agency and oversight; technical robustness and safety; privacy and data governance; transparency; diversity, non-discrimination and  fairness;  societal  and  environmental  well-being  and  accountability.  Without  prejudice  to  the  legally  binding requirements  of  this  Regulation  and  any  other  applicable  Union  law,  those  guidelines  contribute  to  the  design  of coherent,  trustworthy  and  human-centric  AI,  in  line  with  the  Charter  and  with  the  values  on  which  the  Union  is founded.  According  to  the  guidelines  of  the  AI  HLEG,  human  agency  and  oversight  means  that  AI  systems  are developed  and  used  as  a  tool  that  serves  people,  respects  human  dignity  and  personal  autonomy,  and  that  is functioning in a way that can be appropriately controlled and overseen by humans. Technical robustness and safety means that AI systems are developed and used in a way that allows robustness in the case of problems and resilience against attempts to alter  the use or  performance of  the AI system so as to allow unlawful use by third parties, and minimise  unintended  harm.  Privacy  and  data  governance  means  that  AI  systems  are  developed  and  used  in accordance  with  privacy  and  data  protection  rules,  while  processing  data  that  meets  high  standards  in  terms  of quality and integrity. Transparency means that AI systems are developed and used in a way that allows appropriate traceability and explainability, while making humans aware that they communicate or interact with an AI system, as well as duly informing deployers of the capabilities and limitations of that AI system and affected persons about their rights.  Diversity,  non-discrimination  and  fairness  means  that  AI  systems  are  developed  and  used  in  a  way  that includes diverse actors and promotes  equal access, gender equality and cultural diversity, while avoiding discriminatory  impacts  and  unfair  biases  that  are  prohibited  by  Union  or  national  law.  Social  and  environmental well-being means that AI systems are developed and used in a sustainable and environmentally friendly manner as well  as  in  a  way  to  benefit  all  human  beings,  while  monitoring  and  assessing  the  long-term  impacts  on  the individual,  society  and  democracy.  The  application  of  those  principles  should  be  translated,  when  possible,  in  the design and use of AI models. They should in any case serve as a basis for the drafting of codes of conduct under this Regulation.  All  stakeholders,  including  industry,  academia,  civil  society  and  standardisation  organisations,  are encouraged  to  take  into  account,  as  appropriate,  the  ethical  principles  for  the  development  of  voluntary  best practices  and  standards.
- (28) Aside  from  the  many  beneficial  uses  of  AI,  it  can  also  be  misused  and  provide  novel  and  powerful  tools  for manipulative,  exploitative  and  social  control  practices.  Such  practices  are  particularly  harmful  and  abusive  and should  be  prohibited  because  they  contradict  Union  values  of  respect  for  human  dignity,  freedom,  equality, democracy  and  the  rule  of law  and  fundamental  rights  enshrined in the Charter, including the right to non-discrimination,  to data  protection  and  to  privacy  and  the  rights  of  the  child.
- (29) AI-enabled  manipulative  techniques  can  be  used  to  persuade  persons  to  engage  in  unwanted  behaviours,  or  to deceive them by nudging them into decisions in a way that subverts and impairs their autonomy, decision-making and  free  choices.  The  placing  on  the  market,  the  putting  into  service  or  the  use  of  certain  AI  systems  with  the objective to or  the effect of materially distorting human behaviour, whereby significant harms, in particular having sufficiently important adverse impacts on physical, psychological health or financial interests are likely to occur, are particularly dangerous and should therefore be prohibited. Such AI systems deploy subliminal components such as audio,  image, video  stimuli  that  persons  cannot  perceive,  as  those  stimuli  are  beyond  human  perception,  or  other manipulative or deceptive techniques that subvert or  impair  person's autonomy, decision-making or free choice in ways  that  people  are  not  consciously  aware  of  those  techniques  or,  where  they  are  aware  of  them,  can  still  be deceived or are not able to control or resist them. 