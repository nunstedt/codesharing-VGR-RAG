## Article  7
## Amendments to Annex III
- 1. The Commission is empowered to adopt delegated acts in accordance with Article 97 to amend Annex III by adding or  modifying  use-cases  of  high-risk  AI  systems  where  both  of  the  following  conditions  are  fulfilled:
- (a) the  AI  systems  are  intended  to  be  used  in  any of  the  areas  listed  in  Annex  III;
- (b) the  AI  systems pose  a  risk of  harm  to health  and  safety,  or  an  adverse  impact  on  fundamental  rights,  and  that  risk  is equivalent to, or greater than, the risk of harm or of adverse impact posed by the high-risk AI systems already referred to  in  Annex  III.
- 2. When assessing  the  condition  under  paragraph  1,  point  (b),  the  Commission  shall  take  into  account  the  following criteria:
- (a) the  intended  purpose  of  the  AI  system;
- (b) the  extent  to  which  an  AI  system  has  been  used  or  is  likely  to  be  used;
- (c) the  nature  and  amount  of  the  data  processed  and  used  by  the  AI  system,  in  particular  whether  special  categories  of personal  data  are  processed;
- (d) the  extent  to  which  the  AI  system  acts  autonomously  and  the  possibility  for  a  human  to  override  a  decision  or recommendations that may lead to potential harm;
- (e) the extent to which the use of an AI system has already caused harm to health and safety, has had an adverse impact on fundamental rights or has given rise to significant concerns in relation to the likelihood of such harm or adverse impact, as demonstrated, for example, by reports or documented allegations submitted to national competent authorities or by other  reports,  as  appropriate;
- (f) the potential extent of such harm or such adverse impact, in particular in terms of its intensity and its ability to affect multiple  persons  or  to  disproportionately  affect  a  particular  group  of  persons;
- (g) the  extent  to  which  persons  who  are  potentially  harmed  or  suffer  an  adverse  impact  are  dependent  on  the  outcome produced with an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;
- (h) the  extent  to  which  there  is  an  imbalance  of  power,  or  the  persons  who  are  potentially  harmed  or  suffer  an  adverse impact  are  in  a  vulnerable  position  in  relation  to  the  deployer  of  an  AI  system,  in  particular  due  to  status,  authority, knowledge, economic or social circumstances, or age;
- (i) the extent to which the outcome produced involving an AI system is easily corrigible or reversible, taking into account the technical solutions available to correct or reverse it, whereby outcomes having an adverse impact on health, safety or fundamental rights, shall  not  be  considered  to  be  easily corrigible  or  reversible;
- (j) the magnitude and likelihood of benefit of the deployment of the AI system for individuals, groups, or society at large, including  possible  improvements in product  safety;
- (k) the  extent  to  which  existing  Union  law  provides  for:
- (i) effective  measures  of  redress  in  relation  to  the  risks  posed  by  an  AI  system,  with  the  exclusion  of  claims  for damages;
- (ii) effective  measures  to  prevent  or  substantially  minimise  those  risks.
- 3. The Commission is empowered to adopt delegated acts in accordance with Article 97 to amend the list in Annex III by removing high-risk AI systems where both of  the  following conditions  are fulfilled:
- (a) the high-risk AI system concerned no longer poses any significant risks to fundamental rights, health or safety, taking into  account  the  criteria  listed  in  paragraph  2;
- (b) the deletion does not decrease the overall level of protection of health, safety and fundamental rights under Union law.
## SECTION 2
## Requirements for high-risk AI systems
## Article  8
## Compliance with the requirements
- 1. High-risk AI systems shall comply with the requirements laid down in this Section, taking into account their intended purpose  as  well  as  the  generally  acknowledged  state  of  the  art  on  AI  and  AI-related  technologies.  The  risk  management system  referred  to  in  Article  9  shall  be  taken  into  account  when  ensuring  compliance  with  those  requirements.
- 2. Where a product contains an AI system, to which the requirements of this Regulation as well as requirements of the Union harmonisation legislation listed in Section A of Annex I apply, providers shall be responsible for ensuring that their product is fully compliant with all applicable requirements under applicable Union harmonisation legislation. 