In ensuring the compliance of high-risk AI systems referred to in paragraph 1 with the requirements set out in this Section, and in order to ensure consistency, avoid duplication and minimise additional burdens, providers shall have a choice of integrating, as appropriate,  the  necessary  testing  and  reporting  processes,  information  and  documentation  they  provide  with  regard  to their  product  into  documentation  and  procedures  that  already  exist  and  are  required  under  the  Union  harmonisation legislation  listed  in  Section  A  of  Annex  I.
## Article  9
## Risk management system
- 1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems.
- 2. The risk management system shall be understood as a continuous iterative process planned and run throughout the entire  lifecycle  of a  high-risk  AI  system,  requiring  regular  systematic review  and  updating.  It  shall  comprise  the  following steps:
- (a) the identification and analysis of the known and the reasonably foreseeable risks that the high-risk AI system can pose to health, safety or  fundamental rights when the high-risk AI system is used in accordance with its intended purpose;
- (b) the estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended  purpose,  and  under  conditions  of  reasonably  foreseeable  misuse;
- (c) the evaluation of other risks possibly arising, based on the analysis of data gathered from the post-market monitoring system  referred  to  in  Article  72;
- (d) the adoption of appropriate and targeted risk management measures designed to address the risks identified pursuant to point  (a).
- 3. The risks referred to in this Article shall concern only those which may be reasonably mitigated or eliminated through the  development or design  of  the  high-risk  AI  system,  or  the  provision  of  adequate  technical  information.
- 4. The risk management measures referred to in paragraph 2, point (d), shall give due consideration to the effects and possible  interaction  resulting  from  the  combined  application  of  the  requirements  set  out  in  this  Section,  with  a  view  to minimising  risks  more  effectively  while  achieving  an  appropriate  balance  in  implementing  the  measures  to  fulfil  those requirements.
- 5. The  risk  management  measures  referred  to  in  paragraph  2,  point  (d),  shall  be  such  that  the  relevant  residual  risk associated  with  each hazard,  as  well  as  the  overall  residual  risk  of  the  high-risk  AI  systems  is  judged  to  be  acceptable.
In  identifying  the  most  appropriate  risk  management  measures,  the  following  shall  be  ensured:
- (a) elimination  or  reduction  of  risks  identified  and  evaluated  pursuant  to  paragraph  2  in  as  far  as  technically  feasible through adequate design and  development of  the  high-risk  AI  system;
- (b) where  appropriate,  implementation  of  adequate  mitigation  and  control  measures  addressing  risks  that  cannot  be eliminated;
- (c) provision of  information  required  pursuant  to  Article  13  and,  where  appropriate,  training  to  deployers.
With a view to eliminating or reducing risks related to the use of the high-risk AI system, due consideration shall be given to the technical knowledge, experience, education, the training to be expected by the deployer, and the presumable context in  which  the  system  is  intended  to  be  used.
- 6. High-risk AI systems shall be tested for the purpose of identifying the most appropriate and targeted risk management measures. Testing shall ensure that high-risk AI systems perform consistently for their intended purpose and that they are in compliance with the requirements  set out  in  this  Section.
- 7. Testing  procedures  may  include  testing  in  real-world  conditions  in  accordance  with  Article  60.
- 8. The  testing  of  high-risk  AI  systems  shall  be  performed,  as  appropriate,  at  any  time  throughout  the  development process, and, in any event, prior to their being placed on the market or put into service. Testing shall be carried out against prior defined metrics and probabilistic thresholds that are appropriate to the intended purpose of the high-risk AI system.
- 9. When  implementing  the  risk  management  system  as  provided  for  in  paragraphs  1  to  7,  providers  shall  give consideration  to whether  in  view  of  its  intended  purpose  the  high-risk  AI  system  is  likely  to  have  an  adverse  impact  on persons under  the  age  of  18  and,  as  appropriate,  other  vulnerable  groups.
- 10. For providers of high-risk AI systems that are subject to requirements regarding internal risk management processes under other relevant provisions of Union law, the aspects provided in paragraphs 1 to 9 may be part of, or combined with, the  risk  management  procedures  established  pursuant  to  that  law.
## Article  10
## Data and data governance
- 1. High-risk AI systems which make use of techniques involving the training of AI models with data shall be developed on  the  basis  of  training,  validation  and  testing  data  sets  that  meet  the  quality  criteria  referred  to  in  paragraphs  2  to  5 whenever such data sets are  used.
- 2. Training, validation and testing data sets shall be subject to data governance and management practices appropriate for  the  intended  purpose  of  the  high-risk  AI  system.  Those  practices  shall  concern  in  particular:
- (a) the  relevant  design  choices;
- (b) data  collection  processes  and  the  origin  of  data,  and  in  the  case  of  personal  data,  the  original  purpose  of  the  data collection;
- (c) relevant  data-preparation  processing  operations,  such  as  annotation,  labelling,  cleaning,  updating,  enrichment  and aggregation;
- (d) the formulation of assumptions, in particular with respect to the information that the data are supposed to measure and represent;
- (e) an  assessment of  the  availability,  quantity  and  suitability  of  the  data  sets  that  are  needed;
- (f) examination in view of possible biases that are likely to affect the health and safety of persons, have a negative impact on fundamental rights or lead to discrimination prohibited under Union law, especially where data outputs influence inputs  for  future  operations;
- (g) appropriate measures to detect, prevent  and  mitigate  possible  biases  identified  according  to  point  (f);
- (h) the identification of relevant data gaps or shortcomings that prevent compliance with this Regulation, and how those gaps  and  shortcomings  can  be  addressed.
- 3. Training, validation and testing data sets shall be relevant, sufficiently representative, and to the best extent possible, free of errors and complete in view of the intended purpose. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons in relation to whom the high-risk AI system is intended to be used. 