- 4. Providers  of  general-purpose  AI  models  may  rely  on  codes  of  practice  within  the  meaning  of  Article  56  to demonstrate  compliance  with  the  obligations  set  out  in  paragraph  1  of  this  Article,  until  a  harmonised  standard  is published. Compliance with European harmonised standards grants providers the presumption of conformity to the extent that  those  standards  cover  those  obligations.  Providers  of  general-purpose  AI  models  who  do  not  adhere to an  approved code of practice or do not comply with a European harmonised standard shall demonstrate alternative adequate means of compliance for  assessment by the  Commission.
- 5. For the purpose of facilitating compliance with Annex XI, in particular points 2 (d) and (e) thereof, the Commission is empowered to adopt delegated acts  in  accordance  with  Article  97  to  detail  measurement  and  calculation  methodologies with  a  view  to  allowing  for  comparable  and  verifiable  documentation.
- 6. The Commission is empowered to adopt delegated acts in accordance with Article 97(2) to amend Annexes XI and XII in  light  of  evolving  technological  developments.
- 7. Any  information  or  documentation  obtained  pursuant  to  this  Article,  including  trade  secrets,  shall  be  treated  in accordance with the confidentiality obligations  set out  in  Article  78.
## Article  54
## Authorised representatives of providers of general-purpose AI models
- 1. Prior  to placing a general-purpose AI model on the Union market, providers established in third countries shall, by written  mandate,  appoint  an  authorised  representative  which is  established  in  the  Union.
- 2. The provider shall enable its authorised representative to perform the tasks specified in the mandate received from the provider.
- 3. The  authorised  representative  shall  perform  the  tasks  specified  in  the  mandate  received  from  the  provider.  It  shall provide  a  copy  of  the  mandate  to  the  AI  Office  upon  request,  in  one  of  the  official  languages  of  the  institutions  of  the Union.  For  the  purposes  of  this  Regulation,  the  mandate  shall  empower  the  authorised  representative  to  carry  out  the following  tasks:
- (a) verify  that  the  technical  documentation  specified  in  Annex  XI  has  been  drawn  up  and  all  obligations  referred  to  in Article  53  and,  where  applicable,  Article  55  have  been  fulfilled  by  the  provider;
- (b) keep  a  copy  of  the  technical  documentation  specified  in  Annex  XI  at  the  disposal  of  the  AI  Office  and  national competent authorities, for a period of 10 years after the general-purpose AI model has been placed on the market, and the  contact  details  of  the  provider  that  appointed  the  authorised  representative;
- (c) provide the AI Office, upon a reasoned request, with all the information and documentation, including that referred to in  point  (b),  necessary  to  demonstrate  compliance  with  the  obligations  in  this  Chapter;
- (d) cooperate with the AI Office and competent authorities, upon a reasoned request, in any action they take in relation to the general-purpose AI model, including when the model is integrated into AI systems placed on the market or put into service  in  the  Union.
- 4. The mandate shall empower the authorised representative to be addressed, in addition to or instead of the provider, by the  AI  Office  or  the  competent  authorities,  on  all  issues  related  to  ensuring  compliance  with  this  Regulation.
- 5. The authorised representative shall terminate the mandate if it considers or has reason to consider the provider to be acting contrary to its obligations pursuant to this Regulation. In such a case, it shall also immediately inform the AI Office about the  termination  of  the  mandate and  the  reasons  therefor.
- 6. The obligation set out in this Article shall not apply to providers of general-purpose AI models that are released under a  free  and  open-source  licence  that  allows  for  the  access,  usage,  modification,  and  distribution  of  the  model,  and  whose parameters,  including  the  weights,  the  information  on  the  model  architecture,  and  the  information  on  model  usage,  are made publicly available,  unless  the  general-purpose  AI  models  present  systemic  risks.
## SECTION 3
## Obligations of providers of general-purpose AI models with systemic risk
## Article  55
## Obligations of providers of general-purpose AI models with systemic risk
- 1. In addition to the obligations listed in Articles 53 and 54, providers of general-purpose AI models with systemic risk shall:
- (a) perform model evaluation in accordance with standardised protocols and tools reflecting the state of the art, including conducting and documenting adversarial testing of the model with a view to identifying and mitigating systemic risks;
- (b) assess and mitigate possible systemic risks at Union level, including their sources, that may stem from the development, the  placing  on  the  market,  or  the  use  of  general-purpose  AI  models  with  systemic  risk;
- (c) keep track of, document, and report, without undue delay, to the AI Office and, as appropriate, to national competent authorities,  relevant  information  about  serious  incidents  and  possible  corrective  measures  to  address  them;
- (d) ensure  an  adequate  level  of  cybersecurity  protection  for  the  general-purpose  AI  model  with  systemic  risk  and  the physical  infrastructure  of  the  model.
- 2. Providers  of  general-purpose  AI  models  with  systemic  risk  may  rely  on  codes  of  practice  within  the  meaning  of Article  56  to  demonstrate  compliance  with  the  obligations  set  out  in  paragraph  1  of  this  Article,  until  a  harmonised standard is published. Compliance with European harmonised standards grants providers the presumption of conformity to the extent that those standards cover those obligations. Providers of general-purpose AI models with systemic risks who do not  adhere  to  an  approved  code  of  practice  or  do  not  comply  with  a  European  harmonised  standard  shall  demonstrate alternative  adequate  means  of  compliance  for  assessment  by  the  Commission.
- 3. Any  information  or  documentation  obtained  pursuant  to  this  Article,  including  trade  secrets,  shall  be  treated  in accordance with the confidentiality obligations  set out  in  Article  78.
## SECTION 4
## Codes of practice
## Article  56
## Codes of practice
- 1. The AI Office shall encourage and facilitate the drawing up of codes of practice at Union level in order to contribute to  the  proper  application  of  this  Regulation,  taking  into  account  international  approaches.
- 2. The AI Office and the Board shall aim to ensure that the codes of practice cover at least the obligations provided for in Articles  53  and  55,  including  the  following  issues:
- (a) the  means to ensure that the information referred to in Article 53(1), points (a) and (b), is kept  up to  date in  light of market and technological developments;
- (b) the  adequate  level  of  detail  for  the  summary  about  the  content  used  for  training;
- (c) the identification of the type and nature of the systemic risks at Union level, including their sources, where appropriate;
- (d) the  measures,  procedures  and  modalities  for  the  assessment  and  management  of  the  systemic  risks  at  Union  level, including  the  documentation  thereof,  which shall  be  proportionate  to  the  risks,  take  into  consideration  their  severity and  probability  and  take  into  account  the  specific  challenges  of  tackling  those  risks  in  light  of  the  possible  ways  in which such risks may emerge and materialise along the AI value chain.
- 3. The  AI  Office  may  invite  all  providers  of  general-purpose  AI  models,  as  well  as  relevant  national  competent authorities, to participate in the drawing-up of codes of practice. Civil society organisations, industry, academia and other relevant  stakeholders,  such  as  downstream  providers  and  independent  experts,  may  support  the  process.
- 4. The AI Office and the Board shall aim to ensure that the codes of practice clearly set out their specific objectives and contain  commitments  or  measures,  including  key  performance  indicators  as  appropriate,  to  ensure  the  achievement  of those  objectives,  and  that  they  take  due  account  of  the  needs  and  interests  of  all  interested  parties,  including  affected persons,  at  Union  level.
- 5. The AI Office shall aim to ensure that participants to the codes of practice report  regularly to the AI Office  on  the implementation of  the commitments and the measures taken and their outcomes, including as measured against the key performance indicators as appropriate. Key performance indicators and reporting commitments shall reflect differences in size  and  capacity  between  various  participants.
- 6. The AI Office and the Board shall regularly monitor and evaluate the achievement of  the objectives of  the codes of practice by the participants and their contribution to the proper application of this Regulation. The AI Office and the Board shall  assess  whether  the  codes  of  practice  cover  the  obligations  provided  for  in  Articles  53  and  55,  and  shall  regularly monitor and evaluate the achievement of their objectives. They shall publish their assessment of the adequacy of the codes of  practice.
The Commission may, by way of an implementing act, approve a code of practice and give it a general validity within the Union. That implementing act shall be adopted in accordance with the examination procedure referred to in Article 98(2).
- 7. The AI Office may invite all providers of general-purpose AI models to adhere to the codes of practice. For providers of general-purpose AI models not presenting systemic risks this adherence may be limited to the obligations provided for in Article  53,  unless  they  declare  explicitly  their  interest  to  join  the  full  code.
- 8. The AI Office shall, as appropriate, also encourage and facilitate the review and adaptation of the codes of practice, in particular  in  light  of  emerging  standards.  The  AI  Office  shall  assist  in  the  assessment  of  available  standards.
- 9. Codes of practice shall be ready at the latest by 2 May 2025. The AI Office shall take the necessary steps, including inviting  providers  pursuant  to  paragraph  7.
- If,  by  2  August  2025,  a  code  of  practice  cannot  be  finalised,  or  if  the  AI  Office  deems  it  is  not  adequate  following  its assessment under paragraph 6 of this Article, the Commission may provide, by means of implementing acts, common rules for the implementation of the obligations provided for in Articles 53 and 55, including the issues set out in paragraph 2 of this Article. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 98(2).
## MEASURES IN SUPPORT OF INNOVATION
## Article  57
## AI regulatory sandboxes
- 1. Member States shall ensure that their competent authorities establish at least one AI regulatory sandbox at national level,  which  shall  be  operational  by  2  August  2026.  That  sandbox  may  also  be  established  jointly  with  the  competent authorities of other Member States. The Commission may provide technical support, advice and tools for the establishment and operation  of  AI  regulatory  sandboxes.
The obligation under  the first  subparagraph may also be fulfilled  by participating in an existing sandbox in so far as that participation provides an  equivalent  level  of  national  coverage  for  the  participating  Member  States.
- 2. Additional AI regulatory sandboxes at regional or local level, or established jointly with the competent authorities of other  Member States may also be  established.
- 3. The European Data Protection Supervisor may also establish an AI regulatory sandbox for Union institutions, bodies, offices  and  agencies,  and  may  exercise  the  roles  and  the  tasks  of  national  competent  authorities  in  accordance  with  this Chapter.
- 4. Member  States  shall  ensure  that  the  competent  authorities  referred  to  in  paragraphs  1  and  2  allocate  sufficient resources to comply with this Article effectively and in a timely manner. Where appropriate, national competent authorities shall cooperate with other relevant authorities, and may allow for the involvement of other actors within the AI ecosystem. This Article shall not affect other regulatory sandboxes established under Union or national law. Member States shall ensure an appropriate level of cooperation between the authorities supervising those other sandboxes and the national competent authorities.
- 5. AI  regulatory  sandboxes  established  under  paragraph  1  shall  provide  for  a  controlled  environment  that  fosters innovation  and  facilitates  the  development,  training,  testing  and  validation  of  innovative  AI  systems  for  a  limited  time before  their  being  placed  on  the  market  or  put  into  service  pursuant  to  a  specific  sandbox  plan  agreed  between  the providers  or  prospective  providers  and  the  competent  authority.  Such  sandboxes  may  include  testing  in  real  world conditions  supervised  therein.
- 6. Competent  authorities  shall  provide,  as  appropriate,  guidance,  supervision  and  support  within  the  AI  regulatory sandbox with a view to identifying risks, in particular to fundamental rights, health and safety, testing, mitigation measures, and their effectiveness in relation to the obligations and requirements of this Regulation and, where relevant, other Union and national  law  supervised  within  the  sandbox.
- 7. Competent authorities shall provide providers and prospective providers participating in the AI regulatory sandbox with  guidance  on  regulatory expectations  and  how  to  fulfil  the  requirements  and  obligations  set  out  in  this  Regulation.
Upon request of  the  provider  or  prospective  provider  of  the  AI  system,  the  competent  authority  shall  provide  a  written proof of  the  activities  successfully  carried  out  in  the  sandbox.  The  competent  authority  shall  also  provide  an  exit  report detailing  the  activities  carried  out  in  the  sandbox  and  the  related  results  and  learning  outcomes.  Providers  may  use  such documentation  to  demonstrate  their  compliance  with  this  Regulation  through  the  conformity  assessment  process  or relevant  market  surveillance  activities.  In  this  regard,  the  exit  reports  and  the  written  proof  provided  by  the  national competent  authority  shall  be  taken  positively  into  account  by  market  surveillance  authorities  and  notified  bodies,  with a  view  to  accelerating  conformity  assessment  procedures  to  a  reasonable  extent.
- 8. Subject to the confidentiality provisions in Article 78, and with the agreement of the provider or prospective provider, the  Commission  and  the  Board  shall  be  authorised  to  access  the  exit  reports  and  shall  take  them  into  account,  as appropriate, when exercising their tasks under this Regulation. If both the provider or prospective provider and the national competent  authority  explicitly  agree,  the  exit  report  may  be  made  publicly  available  through  the  single  information platform referred  to  in  this  Article.
- 9. The establishment of AI regulatory sandboxes shall  aim to contribute to the  following objectives:
- (a) improving legal  certainty  to  achieve  regulatory  compliance  with  this  Regulation  or,  where  relevant,  other  applicable Union and national law;
- (b) supporting  the  sharing  of  best  practices  through  cooperation  with  the  authorities  involved  in  the  AI  regulatory sandbox;
- (c) fostering  innovation  and  competitiveness  and  facilitating  the  development  of  an  AI  ecosystem;
- (d) contributing  to  evidence-based  regulatory  learning;
- (e) facilitating and accelerating access to the Union market for AI systems, in particular when provided by SMEs, including start-ups.
- 10. National competent authorities shall ensure that, to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to data, the national data protection authorities and those other national or competent authorities are associated with the operation of the AI regulatory sandbox and involved in the supervision of those aspects to the extent of their  respective  tasks  and  powers.
- 11. The  AI  regulatory  sandboxes  shall  not  affect  the  supervisory  or  corrective  powers  of  the  competent  authorities supervising the sandboxes, including at regional or local level. Any significant risks to health and safety and fundamental rights  identified  during  the  development  and  testing  of  such  AI  systems  shall  result  in  an  adequate  mitigation.  National competent authorities shall have the power to temporarily or permanently suspend the testing process, or the participation in  the  sandbox  if  no  effective  mitigation  is  possible,  and  shall  inform  the  AI  Office  of  such  decision.  National  competent authorities  shall  exercise  their  supervisory  powers  within  the  limits  of  the  relevant  law,  using  their  discretionary  powers when implementing legal provisions in respect of a specific AI regulatory sandbox project, with the objective of supporting innovation  in  AI  in  the  Union.
- 12. Providers and prospective providers participating in the AI regulatory sandbox shall remain liable under applicable Union and national liability law for any damage inflicted on third parties as a result of the experimentation taking place in the sandbox. However, provided that the prospective providers observe the specific plan and the terms and conditions for their participation and follow in good faith the guidance given by the national competent authority, no administrative fines shall be imposed by the authorities for infringements of this Regulation. Where other competent authorities responsible for other  Union  and  national  law  were  actively  involved  in  the  supervision  of  the  AI  system  in  the  sandbox  and  provided guidance for  compliance, no administrative  fines  shall  be  imposed  regarding  that  law.
- 13. The AI regulatory sandboxes shall be designed and implemented in such a way that, where relevant, they facilitate cross-border  cooperation  between  national  competent  authorities.
- 14. National  competent authorities  shall  coordinate their  activities  and  cooperate  within  the  framework of  the  Board.
- 15. National competent authorities shall inform the AI Office and the Board of the establishment of a sandbox, and may ask them for support and guidance. The AI Office shall make publicly available a list of planned and existing sandboxes and keep it  up  to  date  in  order  to  encourage  more  interaction  in  the  AI  regulatory  sandboxes  and  cross-border  cooperation.
- 16. National competent authorities shall submit annual reports to the AI Office and to the Board, from one year after the  establishment  of  the  AI  regulatory  sandbox  and  every  year  thereafter  until  its  termination,  and  a  final  report.  Those reports  shall  provide  information  on  the  progress  and  results  of  the  implementation  of  those  sandboxes,  including  best practices, incidents, lessons learnt and recommendations on their setup and, where relevant, on the application and possible revision  of  this  Regulation,  including  its  delegated  and  implementing  acts,  and  on  the  application  of  other  Union  law supervised by the competent authorities within the sandbox. The national competent authorities shall make those annual reports  or  abstracts  thereof  available  to  the  public,  online.  The  Commission  shall,  where  appropriate,  take  the  annual reports  into  account  when  exercising  its  tasks  under  this  Regulation.
- 17. The  Commission  shall  develop  a  single  and  dedicated  interface  containing  all  relevant  information  related  to  AI regulatory sandboxes to allow stakeholders to interact with AI regulatory sandboxes and to raise enquiries with competent authorities,  and  to  seek  non-binding  guidance  on  the  conformity  of  innovative  products,  services,  business  models embedding AI technologies, in accordance with Article 62(1), point (c). The Commission shall proactively coordinate with national  competent  authorities,  where  relevant.
