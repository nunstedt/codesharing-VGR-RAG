- 10. Member States shall facilitate coordination between market surveillance authorities designated under this Regulation and other relevant national authorities or bodies which supervise the application of Union harmonisation legislation listed in  Annex  I,  or  in  other  Union  law,  that  might  be  relevant  for  the  high-risk  AI  systems  referred  to  in  Annex  III.
- 11. Market  surveillance  authorities  and  the  Commission  shall  be  able  to  propose  joint  activities,  including  joint investigations, to be conducted by either market surveillance authorities or market surveillance authorities jointly with the Commission,  that  have  the  aim  of  promoting  compliance,  identifying  non-compliance,  raising  awareness  or  providing guidance in relation to this Regulation with respect to specific categories of high-risk AI systems that are found to present a serious risk across two or more Member States in accordance with Article 9 of Regulation (EU) 2019/1020. The AI Office shall  provide  coordination  support  for  joint  investigations.
- 12. Without prejudice to the powers provided for under Regulation (EU) 2019/1020, and where relevant and limited to what  is  necessary  to  fulfil  their  tasks,  the  market  surveillance  authorities  shall  be  granted  full  access  by  providers  to  the documentation as well as the training, validation  and  testing  data  sets  used  for  the  development  of  high-risk  AI  systems, including, where appropriate and subject to security safeguards, through application programming interfaces (API) or other relevant  technical  means  and  tools  enabling  remote  access.
- 13. Market surveillance authorities shall be granted access to the source code of the high-risk AI system upon a reasoned request  and  only  when  both  of  the  following  conditions  are  fulfilled:
- (a) access  to  source  code  is  necessary  to  assess  the  conformity of  a  high-risk  AI  system  with  the  requirements  set  out  in Chapter III,  Section  2;  and
- (b) testing  or  auditing  procedures  and  verifications  based  on  the  data  and  documentation  provided  by  the  provider  have been  exhausted  or  proved  insufficient.
- 14. Any information or documentation obtained by market surveillance authorities shall be treated in accordance with the  confidentiality  obligations  set  out  in  Article  78.
## Article  75
## Mutual assistance,  market surveillance and control of general-purpose AI systems
- 1. Where an AI system is  based  on  a  general-purpose  AI  model,  and  the  model  and  the  system  are  developed  by  the same provider,  the  AI  Office  shall  have  powers  to  monitor  and  supervise  compliance  of  that  AI  system  with  obligations under this Regulation. To carry out its monitoring and supervision tasks, the AI Office shall have all the powers of a market surveillance  authority  provided  for  in  this  Section  and  Regulation  (EU)  2019/1020.
- 2. Where the relevant market surveillance authorities have sufficient reason to consider general-purpose AI systems that can be used directly  by  deployers  for  at  least  one  purpose  that  is  classified  as  high-risk  pursuant  to  this  Regulation  to  be non-compliant  with  the  requirements  laid  down  in  this  Regulation,  they  shall  cooperate  with  the  AI  Office  to  carry  out compliance evaluations,  and  shall  inform  the  Board  and  other  market  surveillance  authorities  accordingly.
- 3. Where a market surveillance authority is unable to conclude its investigation of the high-risk AI system because of its inability to access certain information related to the general-purpose AI model despite having made all appropriate efforts to obtain that information, it may submit a reasoned request to the AI Office, by which access to that information shall be enforced. In that case, the AI Office shall supply to the applicant authority without delay, and in any event within 30 days, any  information  that  the  AI  Office  considers  to  be  relevant  in  order  to  establish  whether  a  high-risk  AI  system  is non-compliant.  Market  surveillance  authorities  shall  safeguard  the  confidentiality  of  the  information  that  they  obtain  in accordance with Article  78  of  this  Regulation.  The  procedure  provided  for  in  Chapter  VI  of  Regulation  (EU)  2019/1020 shall  apply mutatis  mutandis .
## Article  76
## Supervision of  testing  in  real  world  conditions  by market surveillance  authorities
- 1. Market surveillance authorities shall have competences and powers to ensure that testing in real world conditions is in accordance with this  Regulation.
- 2. Where  testing  in  real  world  conditions  is  conducted  for  AI  systems  that  are  supervised  within  an  AI  regulatory sandbox under Article 58, the market surveillance authorities shall verify the compliance with Article 60 as part of  their supervisory  role  for  the  AI  regulatory  sandbox.  Those  authorities  may,  as  appropriate,  allow  the  testing  in  real  world conditions  to be  conducted  by the  provider  or  prospective  provider,  in  derogation  from  the  conditions  set out  in  Article 60(4),  points  (f)  and  (g).
- 3. Where a market surveillance authority has been informed by the prospective provider, the provider or any third party of a serious incident or has other grounds for considering that the conditions set out in Articles 60 and 61 are not met, it may take either  of  the  following  decisions  on  its  territory,  as  appropriate:
- (a) to  suspend  or  terminate  the  testing  in  real  world  conditions;
- (b) to require  the  provider  or  prospective  provider and  the deployer or  prospective deployer  to modify  any aspect of  the testing  in  real  world  conditions.
- 4. Where a market surveillance authority has taken a decision referred to in paragraph 3 of this Article, or has issued an objection within the meaning of Article 60(4), point (b), the decision or  the objection shall indicate the grounds therefor and how the provider or  prospective  provider  can  challenge  the  decision  or  objection.
- 5. Where  applicable,  where  a  market  surveillance  authority  has  taken  a  decision  referred  to  in  paragraph  3,  it  shall communicate the grounds therefor  to the market surveillance authorities of other Member States in which the AI system has  been  tested  in  accordance  with  the  testing  plan.
## Article  77
## Powers of authorities protecting fundamental rights
- 1. National  public  authorities  or  bodies  which  supervise  or  enforce  the  respect  of  obligations  under  Union  law protecting  fundamental  rights,  including  the  right  to  non-discrimination,  in  relation  to  the  use  of  high-risk  AI  systems referred  to  in  Annex  III  shall  have  the  power  to  request  and  access  any  documentation  created  or  maintained  under  this Regulation in accessible language and format when access to that documentation is necessary for effectively fulfilling their mandates within the limits of their jurisdiction. The relevant public authority or body shall inform the market surveillance authority of  the  Member  State  concerned  of any such  request.
- 2. By 2 November 2024, each Member State shall identify the public authorities or bodies referred to in paragraph 1 and make a  list  of  them  publicly  available.  Member  States  shall  notify  the  list  to  the  Commission  and  to  the  other  Member States,  and  shall  keep  the  list  up  to  date.
- 3. Where  the  documentation  referred  to  in  paragraph  1  is  insufficient  to  ascertain  whether  an  infringement  of obligations  under  Union  law  protecting  fundamental  rights  has  occurred,  the  public  authority  or  body  referred  to  in paragraph  1  may  make  a  reasoned  request  to  the  market  surveillance  authority,  to  organise  testing  of  the  high-risk  AI system through technical means. The market surveillance authority shall organise the testing with the close involvement of the  requesting  public  authority or  body  within  a  reasonable  time  following  the  request.
- 4. Any information or documentation obtained by the national public authorities or bodies referred to in paragraph 1 of this Article pursuant to this Article shall be treated in accordance with the confidentiality obligations set out in Article 78.
## Article  78
## Confidentiality
- 1. The Commission, market surveillance authorities and notified bodies and any other natural or legal person involved in  the  application  of  this  Regulation  shall,  in  accordance  with  Union  or  national  law,  respect  the  confidentiality  of information and data obtained in  carrying out  their  tasks  and  activities  in  such  a  manner  as  to  protect,  in  particular:
- (a) the  intellectual  property  rights  and  confidential  business  information  or  trade  secrets  of  a  natural  or  legal  person, including  source  code,  except  in  the  cases  referred  to  in  Article  5  of  Directive  (EU)  2016/943  of  the  European Parliament  and  of  the  Council ( 57 );
- (b) the  effective  implementation of  this Regulation, in particular  for  the purposes of  inspections, investigations or audits;
- (c) public  and  national  security  interests;
- (d) the  conduct of  criminal  or  administrative  proceedings;
- (e) information classified  pursuant  to  Union  or  national  law.
- 2. The authorities involved in the application of this Regulation pursuant to paragraph 1 shall request only data that is strictly necessary for the assessment of the risk posed by AI systems and for the exercise of their powers in accordance with this Regulation and with Regulation (EU) 2019/1020. They shall put in place adequate and effective cybersecurity measures to protect the security and confidentiality of the information and data obtained, and shall delete the data collected as soon as it  is  no  longer  needed for  the purpose for  which it was obtained, in accordance with applicable Union or  national law.
- 3. Without  prejudice  to  paragraphs  1  and  2,  information  exchanged  on  a  confidential  basis  between  the  national competent authorities or between national competent authorities and the Commission shall not be disclosed without prior consultation  of  the  originating  national  competent  authority  and  the  deployer  when  high-risk  AI  systems  referred  to  in point 1, 6 or 7 of Annex III are used by law enforcement, border control, immigration or asylum authorities and when such disclosure  would  jeopardise  public  and  national  security  interests.  This  exchange  of  information  shall  not  cover  sensitive operational  data  in  relation  to  the  activities  of  law  enforcement,  border  control,  immigration  or  asylum  authorities.
When the law enforcement, immigration or asylum authorities are providers of high-risk AI systems referred to in point 1, 6  or  7  of  Annex  III,  the  technical  documentation  referred  to  in  Annex  IV  shall  remain  within  the  premises  of  those authorities.  Those  authorities  shall  ensure  that  the  market  surveillance  authorities  referred  to  in  Article  74(8)  and  (9),  as applicable,  can,  upon  request,  immediately  access  the  documentation  or  obtain  a  copy  thereof.  Only  staff  of  the  market surveillance authority holding the appropriate level of security clearance shall be allowed to access that documentation or any copy thereof.
- 4. Paragraphs 1, 2 and 3 shall not affect the rights or obligations of the Commission, Member States and their relevant authorities,  as  well  as  those  of  notified  bodies,  with  regard  to  the  exchange  of  information  and  the  dissemination  of warnings, including in the context of cross-border cooperation, nor shall they affect the obligations of the parties concerned to  provide  information  under  criminal  law of  the  Member  States.
- 5. The Commission and Member States may exchange, where necessary and in accordance with relevant provisions of international and trade agreements, confidential information with regulatory authorities of third countries with which they have  concluded  bilateral  or  multilateral  confidentiality  arrangements  guaranteeing  an  adequate  level  of  confidentiality.
## Article  79
## Procedure at national level for dealing with AI systems  presenting a risk
- 1. AI systems presenting a risk shall be understood as a 'product presenting a risk' as defined in Article 3, point 19 of Regulation  (EU)  2019/1020,  in  so  far  as  they  present  risks  to  the  health  or  safety,  or  to  fundamental  rights,  of  persons.
- 2. Where the market surveillance authority of a Member State has sufficient reason to consider an AI system to present a risk as referred to in paragraph 1 of this Article, it shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation. Particular attention shall be given to AI systems presenting a risk to vulnerable groups. Where risks to fundamental rights are identified, the market surveillance authority shall also inform and fully cooperate with the relevant national public authorities or bodies referred to in Article 77(1).  The  relevant  operators  shall  cooperate  as  necessary  with  the  market  surveillance  authority  and  with  the  other national  public  authorities  or  bodies  referred  to  in  Article  77(1).
- ( 57 ) Directive (EU) 2016/943 of the European Parliament and of the Council of 8 June 2016 on the protection of undisclosed know-how and business information  (trade  secrets)  against  their  unlawful  acquisition,  use  and  disclosure  (OJ  L  157,  ,  p.  1).
Where,  in  the  course  of  that  evaluation,  the  market  surveillance  authority  or,  where  applicable  the  market  surveillance authority in cooperation with the national public authority referred to in Article 77(1), finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without undue delay require the relevant operator to take all appropriate corrective actions to bring the AI system into compliance, to withdraw the AI system from the  market,  or  to  recall  it  within  a  period  the  market  surveillance  authority  may  prescribe,  and  in  any  event  within  the shorter  of  15  working  days,  or  as  provided  for  in  the  relevant  Union  harmonisation  legislation.
The  market  surveillance  authority  shall  inform  the  relevant  notified  body  accordingly.  Article  18  of  Regulation  (EU) 2019/1020 shall apply to the measures referred to in the  second  subparagraph  of  this  paragraph.
- 3. 