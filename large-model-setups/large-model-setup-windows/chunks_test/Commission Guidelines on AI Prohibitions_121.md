A biometric identification system (not remote) verifies whether people have access to a nuclear energy plant. When people present themselves in front of the (obvious) camera and access is refused by the system, the system subsequently tries to identify whether the person is on a watchlist of terrorists. The system is not remote. Persons were actively participating in the verification exercise to gain admission to the plant. The use-case does not fall under the prohibition of Article 5 AI Act.
The police authorities of a busy city deploy AI-powered CCTV cameras, which can perform live facial recognition technologies. Possibly, different functionalities are being  added,  such  as  object  detection  and  crowd  movement,  on  top  of  facial recognition.
They  place  these  cameras  at  multiple  locations,  including  places  of  worship,  a number of places frequented by the LGBT+  community,  doctors' offices, pharmacies, and various restaurants and bars.
The installation of biometric-ready cameras as such is not prohibited under the AI Act.
Certain uses however, including the unspecified and indiscriminate identification of natural persons, is prohibited.
Several burglaries occurred in a residential neighbourhood during the summer break. The police obtain a description of the suspect from eyewitnesses, who saw the suspect at different moments in the neighbourhood ahead of the burglaries. To identify and arrest  the  suspect,  the  police  use  live  facial  recognition  technology  at  different locations  in  the  neighbourhood  during  a  weekend.  Based  on  the  indications  of eyewitnesses,  the  police  created  a  facial  composite  of  the  suspect  and  extracted several  pictures  of  individuals  resembling  the  facial  composite  from  a  custody database.
Even if the police use live facial recognition technology against a targeted suspect and have defined a perimeter and time of use, the use is not allowed to be deployed in case of an offence, which is not listed in Annex II of the AI Act.
The  police  screens  the  emotions  of  fans  in  a  football  stadium  with  a  biometric recognition system. The system spots some potential aggression and immediately deploys  in  that  part  of  the  stadium  real-time  RBI  to  identify  hooligans  that  were violent in the past.
The screening of emotions in the stadium is not prohibited under the AI Act (It still falls under the high-risk category of the AI Act). The application of real-time RBI however would be prohibited under the AI Act, in particular where it is the biometric system that decides upon the necessity to identify the persons for the purposes of law enforcement.
The police relies on a CCTV network installed in the city and metro to identify a political protestor that organised a collective protest in the streets. In the Member State concerned, organisers of collective protests held on public roads and public areas, such as streets, must notify the municipal authorities three days in advance of a planned protest to prevent public disorder and violence. The absence of notification is a criminal offence punishable by up to six months imprisonment and a maximum fine of EUR 8 000. To identify the protestor, the police extracts the video feeds from the  CCTV  cameras  installed  in  the  streets  and  performs  retrospective  facial recognition by comparing the extracted images with photographs posted on social media.
The retrospective use of facial recognition technology is not prohibited by the AI Act. That use is considered high-risk and should comply with the requirements in the AI Act for such systems 243 .
Further examples of NOT prohibited practices:
- -Hotels  using  real-time  RBI  to  recognise  VIP  guests.  This  is  not  law enforcement.
- -Shopping  malls  using  real-time  RBI  to  find  shoplifters.  This  is  not  law enforcement.
## Prohibited:
Entrusted  by  the  police,  a  shopping  mall  is  using  real-time  RBI  to  find shoplifters.  The  system  is  deployed  for  law  enforcement  purposes,  in  a publicly  accessible  space.  The  use  is  prohibited  because  the  search  for shoplifters does not fall under any of the exceptions of Article 5(1)(h) AI Act.
## 11. ENTRY INTO APPLICATION
243 The processing of biometric data for a law enforcement purpose remains subject to Article 10 of the LED, which needs to be implemented at national level. Their processing to perform the retrospective use of FRT should only be allowed if it is strictly necessary and should be subject to appropriate safeguards. Whether the retrospective use of FRT is strictly necessary to identify the demonstrator is questionable. In the Glukhin v Russia judgment that serves as a basis for this scenario, the ECtHR ruled that while crime detection can be a legitimate aim, the use of FRT, both retrospective and live, was disproportionate as there were no risks to public order or transport safety. The Court emphasized the 'highly intrusive' nature of FRTs. In that case, the Court concluded that using FRTs did not answer a pressing social need, nor was it necessary in a democratic society.
- (430) According to Article 113 AI Act, Article 5 AI Act applies as from 2 February 2025. The prohibitions in that provision will apply in principle to all AI system regardless of whether they were placed on the market or put into service before or after that date 244 .
- (431) At the same time, the chapters on governance, enforcement and penalties will become applicable  on  2  August  2025.  Consequently,  the  provisions  on  penalties  for  noncompliance with the prohibitions in Article 5 AI Act will not apply before 2 August 2025. In this interim period, there will also be no market surveillance authorities to monitor whether the prohibitions are being properly complied with.
