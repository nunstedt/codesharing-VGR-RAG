Upon a duly substantiated request from the scientific panel, the Commission may issue a request for information to a provider of a general-purpose AI model, where the access to information is necessary and proportionate for the fulfilment of  the  tasks  of  the  scientific  panel  under  Article  68(2).
- 4. The  request  for  information  shall  state  the  legal  basis  and  the  purpose  of  the  request,  specify  what  information  is required, set a period within which the information is to be provided, and indicate the fines provided for in Article 101 for supplying  incorrect,  incomplete or  misleading  information.
- 5. The provider of the general-purpose AI model concerned, or its representative shall supply the information requested. In the case of  legal persons, companies or firms, or where the provider has no legal personality, the persons authorised to represent  them  by  law  or  by  their  statutes,  shall  supply  the  information  requested  on  behalf  of  the  provider  of  the general-purpose AI model concerned. Lawyers duly authorised to act may supply information on behalf of their clients. The clients  shall  nevertheless  remain  fully  responsible  if  the  information  supplied  is  incomplete,  incorrect  or  misleading.
## Article  92
## Power  to conduct evaluations
- 1. The AI Office,  after  consulting  the  Board,  may conduct evaluations  of  the  general-purpose  AI  model  concerned:
- (a) to assess compliance of the provider with obligations under this Regulation, where the information gathered pursuant to  Article  91  is  insufficient;  or
- (b) to  investigate  systemic  risks  at  Union  level  of  general-purpose  AI  models  with  systemic  risk,  in  particular  following a  qualified  alert  from  the  scientific  panel  in  accordance  with  Article  90(1),  point  (a).
- 2. The Commission may decide to appoint independent experts to carry out evaluations on its behalf, including from the scientific  panel  established  pursuant  to  Article  68.  Independent  experts  appointed  for  this  task  shall  meet  the  criteria outlined  in  Article  68(2).
- 3. For  the  purposes  of  paragraph  1,  the  Commission  may  request  access  to  the  general-purpose  AI  model  concerned through APIs or  further  appropriate  technical  means  and  tools,  including  source  code.
- 4. The  request  for  access  shall  state  the  legal  basis,  the  purpose  and  reasons  of  the  request  and  set  the  period  within which the access  is  to  be  provided,  and  the  fines  provided  for  in  Article  101  for  failure  to  provide  access.
- 5. The providers of the general-purpose AI model concerned or its representative shall supply the information requested. In the case of  legal persons, companies or firms, or where the provider has no legal personality, the persons authorised to represent  them  by  law  or  by  their  statutes,  shall  provide  the  access  requested  on  behalf  of the  provider  of the general-purpose  AI  model  concerned.
- 6. The  Commission  shall  adopt  implementing  acts  setting  out  the  detailed  arrangements  and  the  conditions  for  the evaluations,  including  the  detailed  arrangements  for  involving  independent  experts,  and  the  procedure  for  the  selection thereof.  Those  implementing  acts  shall  be  adopted  in  accordance  with  the  examination  procedure  referred  to  in  Article 98(2).
- 7. Prior to requesting access to the general-purpose AI model concerned, the AI Office may initiate a structured dialogue with the provider of the general-purpose AI model to gather more information on the internal testing of the model, internal safeguards  for  preventing  systemic  risks,  and  other  internal  procedures  and  measures  the  provider  has  taken  to  mitigate such  risks.
## Article  93
## Power  to request  measures
- 1. Where necessary and appropriate,  the Commission may request providers to:
- (a) take  appropriate measures  to comply  with  the  obligations  set  out  in  Articles  53  and  54;
- (b) implement mitigation measures, where the evaluation carried out in accordance with Article 92 has given rise to serious and substantiated  concern  of a  systemic  risk  at  Union  level;
- (c) restrict  the  making  available  on  the  market,  withdraw  or  recall  the  model.
- 2. Before a measure  is requested, the AI Office may  initiate a structured dialogue with the provider of the general-purpose  AI  model.
- 3. If,  during  the  structured  dialogue  referred  to  in  paragraph  2,  the  provider  of  the  general-purpose  AI  model  with systemic  risk  offers  commitments  to  implement  mitigation  measures  to  address  a  systemic  risk  at  Union  level,  the Commission may, by decision, make those commitments binding and declare that there are no further grounds for action.
## Article  94
## Procedural rights of economic operators of  the general-purpose AI model
Article  18  of  Regulation  (EU)  2019/1020  shall  apply mutatis  mutandis to  the  providers  of  the  general-purpose  AI  model, without prejudice  to more  specific  procedural  rights  provided  for  in  this  Regulation.
## CHAPTER X
## CODES OF CONDUCT AND GUIDELINES
## Article  95
## Codes of conduct for  voluntary application of specific requirements
- 1. The  AI  Office  and  the  Member  States  shall  encourage  and  facilitate  the  drawing  up  of  codes  of  conduct,  including related governance mechanisms, intended to foster the voluntary application to AI systems, other than high-risk AI systems, of some or all of the requirements set out in Chapter III, Section 2 taking into account the available technical solutions and industry  best  practices  allowing  for  the  application  of  such  requirements.
- 2. The  AI  Office  and  the  Member  States  shall  facilitate  the  drawing  up  of  codes  of  conduct  concerning  the  voluntary application,  including  by  deployers,  of  specific  requirements  to  all  AI  systems,  on  the  basis  of  clear  objectives  and  key performance indicators to measure  the achievement of  those  objectives,  including elements  such  as,  but  not  limited  to:
- (a) applicable  elements  provided  for  in  Union  ethical  guidelines  for  trustworthy  AI;
- (b) assessing and minimising the impact of AI systems on environmental sustainability, including as regards energy-efficient programming and techniques for  the efficient  design,  training  and  use  of  AI;
- (c) promoting AI literacy, in particular  that of  persons  dealing  with  the  development,  operation  and  use  of  AI;
- (d) facilitating an inclusive and diverse design of AI systems, including through the establishment of inclusive and diverse development teams and the promotion of stakeholders'  participation in that  process;
- (e) assessing  and  preventing  the  negative  impact  of  AI  systems  on  vulnerable  persons  or  groups  of  vulnerable  persons, including as  regards  accessibility  for  persons  with  a  disability,  as  well  as  on  gender  equality.
- 3. 