The uploaded image will go through the same mathematical transformation as the scraped images.
(233) Where an AI system receives a picture of a person and searches the face on the internet for matches, i.e. 'reverse engineering image search engines', this will be considered to be targeted scraping. Moreover, it is questionable whether the matches would appear in a 'database'.
## . Out of scope
(234) The prohibition in Article 5(1)(e) AI Act does not apply to the untargeted scraping of biometric data other than facial images (such as voice samples).  The prohibition does also not apply where no AI systems are involved in the scraping. Facial image databases that are not used for the recognition of persons are also out of scope, such as facial image databases used for AI model training or testing purposes, where the persons are not identified.
(235) The prohibition in Article 5(1)(e) AI Act does not apply to AI systems which harvest large amounts of facial images from the internet to build AI models that generate new images about fictitious persons because such systems would not result in the recognition of  real  persons.  Such  AI  systems  could  fall  under  the  transparency  requirements  of Article 50 AI Act.
(236) The prohibition in Article 5(1)(e) AI Act covers AI systems used to create or expand facial recognition databases. When it comes to existing facial databases built up prior
to the entry into application of the prohibition, which are not further expanded through AI-enabled untargeted scraping, those databases and their use must comply with the applicable Union data protection rules.
(237) The prohibition in Article 5(1)(e) AI Act is targeted at the creation or expansion of facial recognition databases. The concrete act of biometric identification is subject to specific rules in the AI Act and other relevant Union legislation.
## . Interplay with other Union legal acts
(238) In relation to Union data protection law, the untargeted scraping of the internet or CCTV material  to  build-up  or  expand  face  recognition  databases,  i.e.  the  processing  of personal data (collection of data and use of databases) would be unlawful and no legal basis under the GDPR, EUDPR and the LED could be relied upon.
## 7. ARTICLE 5(1)(F) AI ACT EMOTION RECOGNITION
(239) Article 5(1)(f) AI Act prohibits AI systems to infer emotions of a natural person in the areas of workplace and education institutions, except where the use of the system is intended for medical or safety reasons. Emotion recognition systems that do not fall under the prohibition are considered high-risk pursuant to point (1)(c) of Annex III AI Act. Article 50(3) AI Act lays down certain transparency requirements for the use of emotion recognition systems.
## . 