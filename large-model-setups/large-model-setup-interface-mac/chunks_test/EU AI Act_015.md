Therefore, the placing on the market, the putting into service, or the use of AI systems intended to be used to detect the emotional state of individuals in situations related to the workplace and education  should  be  prohibited.  That  prohibition  should  not  cover  AI  systems  placed  on  the  market  strictly  for medical or  safety  reasons,  such  as  systems  intended  for  therapeutical  use.
- (45) Practices  that  are  prohibited  by  Union  law,  including  data  protection  law,  non-discrimination  law,  consumer protection  law,  and  competition  law,  should  not  be  affected  by  this  Regulation.
- (46) High-risk  AI  systems  should  only  be  placed  on  the  Union  market,  put  into  service  or  used  if  they  comply  with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as  recognised  and  protected  by  Union  law.  On  the  basis  of  the  New  Legislative  Framework,  as  clarified  in  the Commission notice 'The 'Blue Guide' on the implementation of EU product rules 2022' ( 20 ),  the general rule is that more  than  one  legal  act  of  Union  harmonisation  legislation,  such  as  Regulations  (EU)  2017/745 ( 21 )  and  (EU) 2017/746 ( 22 )  of  the  European Parliament and of the Council or Directive 2006/42/EC of the European Parliament and of the Council ( 23 ), may be applicable to one product, since the making available or putting into service can take
( 20 ) OJ C 247, , p. 1.
( 21 ) Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017 on medical devices, amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and Regulation (EC) No 1223/2009 and repealing Council Directives 90/385/EEC and 93/42/EEC (OJ L 117, , p. 1).
( 22 ) Regulation (EU) 2017/746 of the European Parliament and of the Council of 5 April 2017 on in vitro diagnostic medical devices and repealing  Directive  98/79/EC  and  Commission  Decision  2010/227/EU  (OJ  L  117,  ,  p.  176).
( 23 ) Directive  2006/42/EC  of  the  European  Parliament  and  of  the  Council  of  17  May  2006  on  machinery,  and  amending  Directive 95/16/EC (OJ L 157, , p. 24).
place  only  when  the  product  complies  with  all  applicable  Union  harmonisation  legislation.  To  ensure  consistency and avoid unnecessary administrative burdens or costs, providers of a product that contains one or more high-risk AI  systems,  to  which  the  requirements  of  this  Regulation  and  of  the  Union  harmonisation  legislation  listed  in  an annex  to  this  Regulation  apply,  should  have  flexibility  with  regard  to  operational  decisions  on  how  to  ensure compliance  of  a  product  that  contains  one  or  more  AI  systems  with  all  applicable  requirements  of  the  Union harmonisation legislation in an optimal manner. AI systems identified  as high-risk  should be limited to those that have  a  significant  harmful  impact  on  the  health,  safety  and  fundamental  rights  of  persons  in  the  Union  and  such limitation  should  minimise  any potential  restriction  to  international  trade.
- (47) AI  systems  could  have  an  adverse  impact  on  the  health  and  safety  of  persons,  in  particular  when  such  systems operate  as  safety  components  of  products.  Consistent  with  the  objectives  of  Union  harmonisation  legislation  to facilitate the free movement of products in the internal market and to ensure that only safe and otherwise compliant products find their  way into the market, it is important that the safety risks that may be generated by a product as a  whole  due  to  its  digital  components,  including  AI  systems,  are  duly  prevented  and  mitigated.  For  instance, increasingly autonomous robots, whether in the context of manufacturing or personal assistance and care should be able to safely operate and performs their functions in complex environments. 