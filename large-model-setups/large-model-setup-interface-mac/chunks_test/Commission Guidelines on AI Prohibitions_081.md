That score is based on relevant personal characteristics,  such  as  age  and  education,  but  also  variables  collected  or inferred  from  data  and  contexts  with  no  apparent  connection  to  the  purpose  of evaluation, such as marital status, health data for chronic diseases, addiction, etc. 123
These unacceptable scoring practices may be distinguished from lawful practices that evaluate persons for specific purpose in compliance with Union and national law, in particular when such laws, in compliance with EU law, specify the data considered as relevant and necessary for the purposes of evaluation (see section . out of scope).
122 For a comparison of a similar national systems of benefits and the social scoring, see D. Hadwick &amp; S. Lan, 'Lessons to be learned from the Dutch childcare allowance scandal: A comparative review of algorithmic governance by tax administrations in the Netherlands, France and Germany' (2021) World Tax Journal, Vol. 13, Issue 4.Familiales (CNAF).
123
A similar system was used in Poland for a system 'Profiling the Unemployed', which was abandoned after it was deemed unconstitutional.
See  Szymielewicz,
Profiling  the  unemployed  in  Poland.:  Social  and  Political  Implications  of  Algorithmic  Decision  Making
,  Fundacja
## Scenario 2: Unfavourable or detrimental treatment disproportionate to the social behaviour
(167) Another  alternative  scenario  under  Article  5(1)(c)(ii)  AI  Act  where  an  AI  scoring system may be prohibited is if the treatment resulting from the score is unjustified or disproportionate to the gravity of the social behaviour. The severity of the impact and the interference with the fundamental rights of the person concerned resulting from the social scoring compared to the gravity of the social behaviour of the person should determine whether such treatment is disproportionate for the legitimate aim pursued, taking into account the general principle of proportionality. This requires a case-bycase assessment, which should consider all relevant circumstances of the case, as well as general ethical considerations and principles for fairness and social justice related to the  assessment  of  the  social  behaviour  and  the  proportionality  of  the  detrimental treatment. The treatment may also be 'unjustified', such as lacking a legitimate aim. Sectoral  Union  or  national  legislation  setting  specific  criteria  and  procedures  that regulate such potential detrimental or unfavourable treatment may also be relevant as part of this assessment.
Examples of unjustified or disproportionate treatment compared to the social behaviour prohibited under Article 5(1)(c) ii) AI Act
- - A public agency uses an AI system to profile families for early detection of children at risk based on criteria such as parental mental health and unemployment, but also information on parents' social behaviour derived from multiple contexts. Based on the resulting score, families are singled out for inspection and children considered 'at risk' are taken from their families, including in cases of minor transgressions by the parents, such as occasionally missing doctors' appointments or receiving traffic fines.
- -  A  municipality  uses  an  AI  system  to  score  trustworthiness  of  residents  based  on multiple  data  points  related  to  their  social  behaviour  in  a  variety  of  contexts.  The generated score for residents considered 'less trustworthy' is used for blacklisting, i.e. withdrawal of public benefits, other serious punitive measures, and increased control or  surveillance.  Among  the  factors  considered  in  the  assessment  are  insufficient volunteering and minor misbehaviour, such as not returning books to the library on time, leaving rubbish on the street outside the day of collection, and a delay in the payment of local taxes.
These unacceptable social scoring practices may be distinguished from lawful practices that evaluate persons for a legitimate specific purpose in compliance with Union and national law, in particular where those laws ensure that detrimental or unfavourable treatment is justified and proportionate to the social behaviour (see section . out of scope).
(168) Both  alternatives  under  Article  5(1)(c)(i)  and  (ii)  AI  Act  may  also  be  fulfilled simultaneously.
Examples of unjustified or disproportionate treatment under Article 5(1)(c)) i) and ii)
AI Act
- -  A  tax  authority  uses  an  AI  system  to  detect  child  benefit  fraud  by  profiling  and assigning beneficiaries suspected of fraud to categories such as 'deliberate intent/gross negligence' using criteria such as low income, dual nationality, social behaviour, etc. Based on the risk score,  a beneficiary's file is  inspected  and,  in  many  cases,  their childcare benefit ceased, they receive notice to repay the received benefits, and no longer qualify for standard debt collection arrangements. Such scoring causes many families to be heavily indebted and leads to unjust, discriminatory and detrimental treatment  of  individuals  and  groups  of  individuals 124 ,  driving  many  families  into severe financial hardship.
- - A public authority uses an AI system to control fraud in the student housing grant process that considers among the indicators the internet connections, family status or level of education of beneficiaries as distinguishing factors for fraud risk, which do not seem relevant, nor justified.
- - A government introduces a comprehensive AI-based system that monitors and rates citizens based on their behaviour in various aspects of life, such as social interactions, online  activities,  purchasing  habits,  and  punctuality  in  paying  bills.  People  with  a lower score face restricted access to public services, higher interest rates on loans, and difficulty in traveling, renting apartments, and even finding jobs. 