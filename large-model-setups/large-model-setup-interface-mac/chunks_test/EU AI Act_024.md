For example, in health, the  European health data  space will  facilitate  non-discriminatory  access  to health  data  and  the training  of  AI  algorithms  on  those  data  sets,  in  a  privacy-preserving,  secure,  timely,  transparent  and  trustworthy manner, and with an appropriate institutional governance. Relevant competent authorities, including sectoral ones, providing  or  supporting  the  access  to  data  may  also  support  the  provision  of  high-quality  data  for  the  training, validation  and  testing  of  AI  systems.
- (69) The right to privacy and to protection of personal data must be guaranteed throughout the entire lifecycle of the AI system. In this regard, the principles of data minimisation and data protection by design and by default, as set out in Union data protection law, are applicable when personal data are processed. Measures taken by providers to ensure compliance  with  those  principles  may  include  not  only  anonymisation  and  encryption,  but  also  the  use  of technology  that  permits  algorithms  to  be  brought  to  the  data  and  allows  training  of  AI  systems  without  the transmission  between  parties  or  copying  of  the  raw  or  structured  data  themselves,  without  prejudice  to  the requirements on data governance provided for  in this  Regulation.
- (70) In  order  to  protect  the  right  of  others  from  the  discrimination  that  might  result  from  the  bias  in  AI  systems,  the providers should, exceptionally, to the extent that it is strictly necessary for  the purpose of ensuring bias detection and correction in relation to the high-risk AI systems, subject to appropriate safeguards for  the fundamental rights and  freedoms  of  natural  persons  and  following  the  application  of  all  applicable  conditions  laid  down  under  this Regulation in addition to the conditions laid down in Regulations (EU) 2016/679 and (EU) 2018/1725 and Directive (EU) 2016/680, be able to process also special categories of personal data, as a matter of substantial public interest within the meaning of Article 9(2), point (g) of Regulation (EU) 2016/679 and Article 10(2), point (g) of Regulation (EU)  2018/1725.
- (71) Having  comprehensible  information  on  how  high-risk  AI  systems  have  been  developed  and  how  they  perform throughout their lifetime is essential to enable traceability of those systems, verify compliance with the requirements under this Regulation, as well as monitoring of their operations and post market monitoring. This requires keeping records  and  the  availability  of  technical  documentation,  containing  information  which  is  necessary  to  assess  the compliance of the AI system with the relevant requirements and facilitate post market monitoring. Such information should  include  the  general  characteristics,  capabilities  and  limitations  of  the  system,  algorithms,  data,  training, testing and validation processes used as well as documentation on the relevant risk-management system and drawn in  a  clear  and  comprehensive  form.  The  technical  documentation  should  be  kept  up  to  date,  appropriately throughout  the  lifetime  of  the  AI  system.  Furthermore,  high-risk  AI  systems  should  technically  allow  for  the automatic  recording  of events,  by  means  of  logs,  over  the  duration  of  the  lifetime  of  the  system.
- (72) To  address  concerns  related  to  opacity  and  complexity  of  certain  AI  systems  and  help  deployers  to  fulfil  their obligations under  this Regulation, transparency should be required for high-risk AI systems before they are placed on the market or  put  it  into service.  High-risk  AI  systems  should  be  designed  in  a  manner  to  enable  deployers  to understand  how  the  AI  system  works,  evaluate  its  functionality,  and  comprehend  its  strengths  and  limitations. High-risk  AI  systems  should  be  accompanied  by  appropriate information  in  the  form  of  instructions  of  use.  Such information should include the characteristics, capabilities and limitations of performance of  the AI system. Those would  cover  information  on  possible  known  and  foreseeable  circumstances  related  to  the  use  of  the  high-risk  AI system, including deployer action that may influence system behaviour and performance, under which the AI system can  lead  to  risks  to  health,  safety,  and  fundamental  rights,  on  the  changes  that  have  been  pre-determined  and assessed for conformity by the provider and on the relevant human oversight measures, including the measures to facilitate  the  interpretation  of the  outputs  of the  AI  system  by  the  deployers.  Transparency,  including  the accompanying instructions for use, should assist deployers in the use of the system and support informed decision making by them. Deployers should, inter alia, be in a better position to make the correct choice of the system that they intend to use in light of the obligations applicable to them, be educated about the intended and precluded uses, and use the AI system correctly and as appropriate. In order to enhance legibility and accessibility of the information included in the instructions of use, where appropriate, illustrative examples, for instance on the limitations and on the intended and  precluded  uses of the AI system, should be included. Providers should ensure that all documentation, including the instructions for use, contains meaningful, comprehensive, accessible and understandable  information,  taking  into  account  the  needs  and  foreseeable  knowledge  of  the  target  deployers. 