who  in  the  value  chain  is  best  placed  to  adopt  specific  preventive  and  mitigating measures and ensure compliant development and use of AI systems in line with the objectives and the approach of the AI Act.
## . Exclusion from the scope of the AI Act
- (21) Article 2 AI Act provides for a number of general exclusions from scope which are relevant for a complete understanding of the practical application of the prohibitions listed in Article 5 AI Act.
## . National security, defence and military purposes
- (22) According to Article 2(3) AI Act, the AI Act does not apply to areas outside the scope of Union law, and should not, in any event, affect the competences of the Member States concerning national security, regardless of the type of entity entrusted by the Member States with carrying out tasks in relation to those competences. The AI Act expressly excludes from its scope AI systems that are 'placed on the market, put into service, or used with or without modification exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.' Whether that exclusion applies therefore depends on the purposes or the uses of the AI system, not the entities carrying out the activities with that system, which may also cover private operators entrusted by the Member States with carrying out tasks in relation to those competences.
- (23) According to the CJEU, the term 'national security ' refers to 'the primary interest in protecting the essential functions of the State and the fundamental interests of society and  encompasses  the  prevention  and  punishment  of  activities  capable  of  seriously destabilising the fundamental constitutional, political, economic or social structures of a country and, in particular, of directly threatening society, the population or the State itself,  such  as  terrorist  activities.' 17 National  security  does  not  cover,  for  example activities relating to road safety, 18 or the organisation or administration of justice. 19 As stated  by  the  CJEU,  'it  is  for  the  Member  States  to  define  their  essential  security interests and to adopt appropriate measures to ensure their internal and external security, [….]  a  national  measure  […]  taken  for  the  purpose  of  protecting  national  security cannot render EU law inapplicable and exempt the Member States from their obligation to comply with that law.' 20
- (24) For the exclusion in Article 2(3), second subparagraph, AI Act to apply, the AI system must be placed on the market, put into service or used exclusively for military, defence or  national  security  purposes.  Recital  24  AI  Act  further  clarifies  how  the  notion
17 Judgment of the Court of Justice of 6 October 2020, La Quadrature du Net and Others , C-511/18, C-512/18
and C-520/18,EU:C:2020:791, paragraph 135; Judgment of the Court of Justice of 5 June 2023,
Commission
v
Poland
, C-204/21,
EU:C:2023:442, paragraph 318, referring to Case C-439/19, paragraph 67 and Case C-306/21, paragraph 40.
18 Judgment of the Court of Justice of 22 June 2021, Latvijas Republikas Saeima , C-439/19, EU:C:2021:504, paragraph 68.
19 Judgment of the Court of Justice of 5 June 2023, Commission v Poland , C-204/21, EU:C:2023:442, paragraph 319.
20 Judgement of the Court of Justice of 6 October 2020, Privacy International, C-623/17, EU:C:2020:790, paragraph 44.
' exclusively' should be interpreted and when an AI system used for such purposes may nevertheless fall within the scope of the AI Act.
For example, if an AI system placed on the market, put into service or used for military, defence or national security purposes is used (temporarily or permanently) for other purposes,  such  as  for  civilian  or  humanitarian  purposes,  law  enforcement  or  public security purposes, that system will fall within the scope of the AI Act. In that case, the entity using the AI system for the other purposes should ensure compliance of the AI system with the AI Act, unless the system already complies with that act, which has to be verified before such use.
- (25) Furthermore, recital 24 AI Act clarifies that AI systems placed on the market or put into service for an excluded purpose, namely military, defence or national security, and for one or more non-excluded purposes, such as civilian or law enforcement purposes (so called  ' dual  use' systems),  fall  within  the  scope  of  the  AI  Act.  Providers  of  those systems should ensure that they comply with the requirements in the AI Act.
For example, if a company offers a RBI system for various purposes, including law enforcement  and  national  security,  that  company  is  the  provider  of  that  'dual  use' system and must ensure its compliance with the requirements in the AI Act.
- (26) However, the fact that an AI system may fall within the scope of the AI Act should not affect the ability of entities carrying out national security, defence and military activities to use that system for national security, military and defence purposes, regardless of the type of entity carrying out those activities 21 .
For example, if a national security agency or a private operator is tasked by a national intelligence agency to use real-time RBI systems for national security purposes (such as to gather intelligence), such use would be excluded from the scope of the AI Act.
- (27) The clear delineation of the national security exclusion is particularly important where AI systems are placed on the market, put into service  or  used  for  law  enforcement purposes that fall within the scope of the AI Act. This is relevant for the prohibitions regarding individual crime predictions and assessments and regarding the use of realtime RBI systems for law enforcement purposes laid down in Article 5(1)(d) and (h) AI Act  respectively.  Police  and  other  law  enforcement  authorities  are  tasked  with  the prevention,  detection,  investigation  and  prosecution  of  criminal  offences  or  the execution of criminal penalties, including safeguarding against and preventing threats to public security 22 .  Whenever AI systems are used for such purposes, they will fall within the scope of the AI Act.
21 Recital 24 AI Act.
22 Article 3(46) AI Act.
- (28) The activities of Europol and other Union security agencies, such as Frontex, fall within the scope of the AI Act.
## . Judicial and law enforcement cooperation with third countries
- (29) According to Article 2(4) AI Act, the AI Act does not apply to public authorities in a third country or international organisations, where those authorities or organisations use AI  systems  in  the  framework  of  international  cooperation  or  agreements  for  law enforcement and judicial  cooperation  with  the  Union  or  with  one  or  more  Member States,  provided  that  such  a  third  country  or  international  organisation  provides adequate safeguards with respect to the protection of fundamental rights and freedoms of individuals. Where relevant, this exclusion may cover the activities of private entities entrusted by the third country in question to carry out specific tasks in support of such law  enforcement  and  judicial  cooperation. 23 At  the  same  time,  for  the  exclusion  to apply,  these  frameworks  for  cooperation  or  international  agreements  must  include adequate  safeguards  with  respect  to  the  protection  of  the  fundamental  rights  and freedoms of individuals, to be assessed by the market surveillance authorities competent for the supervision of AI systems used in the area of law enforcement and justice. 24 Recital 22 AI Act clarifies that the recipient national authorities and Union institutions, bodies,  offices  and  agencies  making  use  of  such  AI  outputs  in  the  Union  remain accountable to ensure their use complies with Union law. When those international agreements are revised or new ones are concluded in the future, the contracting parties should make utmost efforts to align those agreements with the requirements of the AI Act.
## . Research &amp; Development
- (30) According to Article 2(8) AI Act, the AI Act does not apply 'to any research, testing or development activity regarding AI systems or AI models prior to their being placed on the market or put into service'. This exclusion is in line with the market-based logic of the AI Act, which applies to AI systems once they are placed on the market or put into service.
For example, during the research and development (R&amp;D) phase, AI developers have the freedom to experiment and test new functionalities which might involve techniques that could be seen as manipulative and covered by Article 5(1)(a) AI Act, if used in consumer-facing  applications.  