150 Recital 44 AI Act explains that there are 'serious concerns about the scientific basis of AI systems aiming to identify or infer emotions, particularly as expression of emotions vary considerably across cultures and situations, and even within a single individual. Among the key shortcomings of such systems are the limited reliability, the lack of specificity and the limited generalisability.' It further explains that emotion recognition can lead to 'discriminatory outcomes and can be intrusive to the rights and freedoms of the concerned persons', in particular the rights to privacy, human dignity and freedom of thought. This plays an important role in asymmetric relationships especially in the context of the workplace and education and training institutions, where both workers and  students  are  in  particularly  vulnerable  positions.  At  the  same  time,  emotion recognition in specific use contexts, such as for safety and medical care (e.g. health treatment and diagnosis) has benefits. 151
## . Main concepts and components of the prohibition
## Article 5(1) (f) AI Act provides:
The following AI practices shall be prohibited:
f) the placing on the market, the putting into service for this specific purpose, or the use of  AI  systems  to  infer  emotions  of  a  natural  person  in  the  areas  of  workplace  and education institutions, except where the use of the AI system is intended to be put in place or into the market for medical or safety reasons.
(242) Several cumulative conditions must be fulfilled for the prohibition in Article 5(1)(f) AI Act to apply:
- (i) The practice must constitute the 'placing on the market', 'the putting into service for this specific purpose' or the 'use' of an AI system;
- (ii) AI system to infer emotions 152 ;
- (iii) in the area of the workplace or education and training institutions; and
- (iv) excluded from the prohibition are AI systems intended for medical or safety reasons.
(243) For the prohibition to apply all four conditions must be simultaneously fulfilled. The first element, i.e. the placing on the market, putting into service or use of the AI system, has already been analysed in section .. The prohibition, therefore, applies to both
150 See e.g., J. Stanley, Experts Say 'Emotion Recognition' lacks Scientific Foundation, , ACLU, referring to a study by L. Feldman Barrett e.a., 'Emotional Expressions Reconsidered: Challenges to Inferring Emotion From Human Facial Movements', Psychological Science in the Public Interest , 2019, pp.iii-90.
151 See e.g., R. El Kaliouby and R. Picard and S. Baron-Cohen, 'Affective Computing and Autism' , Annals New York Academy of Sciences, 2007, pp.228-248
152 Or the technology is capable of inferring emotions (i.e. when placing it on the market).
providers and deployers of AI systems, each within their respective responsibilities, not to place on the market, put into service or use such AI systems. The other conditions related to the prohibition are further described and analysed below.
## . AI systems to infer emotions
## a) AI systems to infer emotions versus emotion recognition systems
(244) Article  3(39)  AI  Act  defines  'emotion  recognition  systems'  as  AI  systems  'for  the purpose of identifying and inferring emotions or intentions of natural persons on the basis of their biometric data. The prohibition in Article 5(1)(f) AI Act does not refer to 'emotion recognition systems', but only to 'AI systems to infer emotions of a natural person'. Recital 44 further clarifies that that prohibition covers AI systems 'to identify or infer emotions'.
(245) Inferring generally encompasses identifying as a prerequisite, so that the prohibition should be understood as including both AI systems identifying or inferring emotions or intentions. 153 For consistency reasons, it is also important to construe the prohibition in Article 5(1)(f) AI Act as having a similar scope as the rules applicable to other emotion recognition systems (Annex III, point 1(c), and Article 50 AI Act) and to limit it to inferences based on a person's biometric data. The definition in Article 3(39) AI Act of emotion  recognition  systems  should  therefore  be  considered  relevant  in  relation  to Article 5(1)(f) AI Act.
## b) Identification and inference of emotions or intentions
(246) 'Identification' occurs where the processing of the biometric data (for example, of the voice or a facial expression) of a natural person allows to directly compare and identify an emotion with one that has been previously programmed in the emotion recognition system. 'Inferring' is done by deducing information generated by analytical and other processes by the system itself. In such a case, the information about the emotion is not solely based on data collected on the natural person, but it is inferred from other data, including machine learning approaches that learn from data how to detect emotions. 154
## c) Emotions
(247) For the purpose of Article 5(1)(f) AI Act, the concept of emotions or intentions should be  understood  in  a  wide  sense  and  not  interpreted  restrictively.  Recital  18  AI  Act provides  some  detail,  listing  emotions  'such  as  happiness,  sadness,  anger,  surprise, disgust,  embarrassment,  excitement,  shame,  contempt,  satisfaction  and  amusement'. These examples are not exhaustive.
153 See also Recital 18 AI Act.
154 See Recital 12 AI Act. Inferred data is hence also often the result of probability-based analytical (big data) processes aimed at finding correlations and finding patterns in data sets.
(248) The prohibition should not be circumvented by referring to attitudes, and includes cases where the AI system finds on the basis of the biometric data that a person is showing for example an angry attitude.
(249) Recital 18 AI Act clarifies that emotions or intentions do not include 'physical states, such as pain or fatigue, including, for example, systems used in detecting the state of fatigue  of  professional  pilots  or  drivers  for  the  purpose  of  preventing  accidents.'  It further clarifies that emotion recognition systems do not include 'the mere detection of readily  apparent  expressions,  gestures  or  movements,  unless  they  are  used  for identifying or inferring emotions', which should be understood to also apply to Article 5(1)(f) AI Act. Those expressions can be basic facial expressions, such as a frown or a smile, or gestures such as the movement of hands, arms or head, or characteristics of a person's  voice,  such  as  a  raised  voice  or  whispering.  However,  when  these  readily apparent  expressions  or  gestures  are  used  for  identifying  or  inferring  emotions  or intentions, they are covered by the prohibition.
## For example,
- - The observation that a person is smiling is not emotion recognition.
- - Identifying whether a person is sick is not emotion recognition.
- -  A  TV broadcaster using a device that allows to track how many times its news presenters smile to the camera is not emotion recognition.
- - Concluding that a person is happy is emotion recognition. An AI system that infers that  an  employee  is  unhappy,  sad  or  angry  towards  customers  (e.g.  from  body gestures, a frown or the lack of a smile) is 'emotion recognition'.
- - Systems inferring from voice or body gestures, that a student is furious and about to become violent, is 'emotion recognition'.
- - Using AI recognition systems to infer a professional pilot's or driver's fatigue to alert  them  and  suggest  when  to  take  brakes  to  avoid  accidents  is  not  'emotion recognition', since emotion recognition does not include physical states such as pain or fatigue.
## d) On the basis of their biometric data
(250) According to the definition in Article 3(39) AI Act, only AI systems identifying or inferring emotions or intentions based on biometric data constitute emotion recognition systems. 155
155 Article 3(34) AI Act: defines 'biometric data' as 'personal data resulting from specific technical processing relating to the physical, physiological or behavioural characteristics of a natural person, such as facial images or dactyloscopic data'' See also Recital 18 AI Act. About emotion inferences from voice and speech.
- (251) Personal characteristics  from  which biometric data can be extracted are physical or behavioural  attributes.  Physiological  biometrics  employ  physical,  structural,  and relatively static attributes of a person, such as their fingerprints, the pattern of their iris, contours of their face, or the geometry of veins in their hands. Some modalities are microscopic in nature, but still exhibit biological and chemical structures that can be acquired and identified e.g., DNA and odour 156 .  Behavioural biometrics monitor the distinctive characteristics of movements, gestures, and motor-skills of individuals as they perform a task or series of tasks.  This means that human movements, such as walking (gait analysis) or finger contact with a keyboard (keystrokes), are captured and analysed. Behavioural biometrics encompass a variety of modalities that exhibit both voluntary and involuntary repeated motions and associated rhythmic timings/pressures of body features ranging from signatures, gait, voice, and keystrokes through to eye tracking  and  heartbeats 157 ,  electroencephalography  (EEG) 158 ,  or  electrocardiograms (ECG) 159 .  The  biometric  input  can  relate  to  one  modality  (e.g.,  facial  images)  or multiple  modalities  (e.g.,  facial  information  combined  with  electroencephalogram (EEG)). Recital 18 gives as examples facial expressions, gestures such as movement of hands or characteristics of a person's voice.
## For example,
- - An AI system inferring emotions from written text (content/sentiment analyses) to define the style or the tone of a certain article is not based on biometric data and therefore does not fall within the scope of the prohibition.
- -  An  AI  system  inferring  emotions  from  key  stroke  (way  of  typing),  facial expressions, body postures or movements is based on biometric data and falls within the scope of the prohibition.
(252) The AI Act definition of biometric data is therefore broad and includes any biometric data used for emotion recognition, biometric categorisation or other purposes. 160
## . Limitation  of  the  prohibition  to  workplace  and  educational institutions
(253) The prohibition in Article 5(1)(f) AI Act is limited to emotion recognition systems in the 'areas of workplace and educational institutions'. As clarified in recital 44 AI Act,
156 Physiological and Behavioural Biometrics - Biometrics Institute
157 Physiological and Behavioural Biometrics - Biometrics Institute
158 See EDPS, TechDispatch  1/2024 - Neurodata, , in which the use of brain data and related technology is discussed, as well as the legal implication, including the proposition of new 'neurorights', including mental privacy and integrity. In S. O'Sullivan, H. Chneiweiss, A. Pierucci and K. Rommelfanger, Neurotechnologies and Human Rights Framework: Do we need new Human Rights?, Report, OECD and CoE, , p.33 , a state of the art and legal aspects of neurotech is discussed.
159
See Hasnul et al., 2021, Electrocardiogram-Based Emotion Recognition Systems and Their Applications in Healthcare.
160 In the AI Act, the definition of biometric data does not include the wording 'which allow or confirm the unique identification' (the functional use of biometric data), contrary to the definition of biometric data in the GDPR that includes this requirement. The GDPR definition of biometric data will apply under data protection rules with regard to the processing of personal data (and when for example Article 9(1) and 9(2) GDPR would be applicable).
this limitation is meant to address the imbalance of power in the context of work or education.
## a) 'Workplace'
(254) The notion of 'workplace' should be interpreted broadly. That notion relates to any specific physical or virtual space  where  natural persons  engage  in  tasks  and responsibilities assigned by their employer or by the organisation they are affiliated to, for example in case of self-employment. This includes any setting where the work is performed and can vary widely based on the nature of the job, spanning from indoor office  spaces,  factories  and  warehouses  to  publicly  accessible  spaces  like  shops, stadiums or museums, to open-air sites or cars, as well as temporary or mobile work sites. This is independent from the status as an employee, contractor, trainee, volunteer, etc. 