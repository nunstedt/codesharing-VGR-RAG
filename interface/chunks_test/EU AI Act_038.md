- ( 52 ) Council Regulation  (EU)  No  1024/2013 of  15  October  2013  conferring  specific  tasks  on  the  European  Central  Bank  concerning policies  relating  to  the  prudential  supervision  of  credit  institutions  (OJ  L  287,  ,  p.  63).
take  place  at  Union  level  through  the  AI  Office,  which  should  have  the  powers  of  a  market  surveillance  authority within the meaning of Regulation (EU) 2019/1020 for this purpose. In all other cases, national market surveillance authorities remain responsible for the supervision of AI systems. However, for general-purpose AI systems that can be used directly by deployers for at least one purpose that is classified as high-risk, market surveillance authorities should cooperate with the AI Office to carry out evaluations of compliance and inform the Board and other market surveillance authorities accordingly. Furthermore,  market  surveillance  authorities should  be  able to request assistance  from  the  AI  Office  where  the  market  surveillance  authority  is  unable  to  conclude  an  investigation  on a high-risk AI system because of its inability to access certain information related to the general-purpose AI model on which the high-risk AI system is built. In such cases, the procedure regarding mutual assistance in cross-border cases  in  Chapter  VI  of  Regulation  (EU)  2019/1020  should  apply mutatis  mutandis .
- (162) To  make  best  use  of  the  centralised  Union  expertise  and  synergies  at  Union  level,  the  powers  of  supervision  and enforcement  of  the  obligations  on  providers  of  general-purpose  AI  models  should  be  a  competence  of  the Commission. The AI Office should be able to carry out all necessary actions to monitor the effective implementation of  this  Regulation  as  regards  general-purpose  AI  models.  It  should  be  able  to investigate  possible  infringements of the  rules  on  providers  of  general-purpose  AI  models  both  on  its  own  initiative,  following  the  results  of  its monitoring activities, or upon request from market surveillance authorities in line with the conditions set out in this Regulation. To support effective monitoring of the AI Office, it should provide for  the possibility that downstream providers lodge complaints about possible infringements of the rules on providers of general-purpose AI models and systems.
- (163) With a view to complementing the governance systems for general-purpose AI models, the scientific panel should support the monitoring activities of the AI Office and may, in certain cases, provide qualified alerts to the AI Office which trigger  follow-ups,  such  as  investigations.  This  should  be  the  case  where  the  scientific  panel  has  reason  to suspect  that  a  general-purpose  AI  model  poses  a  concrete  and  identifiable  risk  at  Union  level.  Furthermore,  this should be the case where the scientific panel has reason to suspect that a general-purpose AI model meets the criteria that would lead to a classification as general-purpose AI model with systemic risk. To equip the scientific panel with the information necessary for  the performance of those tasks, there should be a mechanism whereby the scientific panel  can  request  the  Commission  to require  documentation  or  information  from  a  provider.
- (164) The  AI  Office  should  be  able  to  take  the  necessary  actions  to  monitor  the  effective  implementation  of  and compliance with the obligations  for  providers  of  general-purpose  AI  models  laid  down  in  this  Regulation.  The  AI Office  should  be  able  to  investigate  possible  infringements  in  accordance  with  the  powers  provided  for  in  this Regulation,  including  by  requesting  documentation  and  information,  by  conducting  evaluations,  as  well  as  by requesting measures from providers of general-purpose AI models. When conducting evaluations, in order to make use  of  independent  expertise,  the  AI  Office  should  be  able  to  involve  independent  experts  to  carry  out  the evaluations on its behalf. Compliance with the obligations should be enforceable, inter alia, through requests to take appropriate measures, including risk mitigation measures in the case of identified systemic risks as well as restricting the making available on the market, withdrawing or recalling the model. As a safeguard, where needed beyond the procedural  rights  provided  for  in  this  Regulation,  providers  of  general-purpose  AI  models  should  have  the procedural  rights  provided  for  in  Article  18  of  Regulation  (EU)  2019/1020,  which  should  apply mutatis  mutandis , without prejudice  to more  specific  procedural  rights  provided  for  by  this  Regulation.
- (165) The  development  of  AI  systems  other  than  high-risk  AI  systems  in  accordance  with  the  requirements  of  this Regulation may lead to a larger uptake of ethical and trustworthy AI in the Union. Providers of AI systems that are not high-risk should be encouraged to create codes of conduct, including related governance mechanisms, intended to foster the voluntary application of some or all of the mandatory requirements applicable to high-risk AI systems, adapted  in  light  of  the  intended  purpose  of  the  systems  and  the  lower  risk  involved  and  taking  into  account  the available technical solutions and industry best practices such as model and data cards. Providers and, as appropriate, deployers of all AI systems, high-risk or not, and AI models should also be encouraged to apply on a voluntary basis additional  requirements  related,  for  example,  to  the  elements  of  the  Union's  Ethics  Guidelines  for  Trustworthy  AI,
environmental  sustainability,  AI  literacy  measures,  inclusive  and  diverse  design  and  development  of  AI  systems, including attention to vulnerable persons and accessibility to persons with disability, stakeholders' participation with the involvement, as appropriate, of relevant stakeholders such as business and civil society organisations, academia, research  organisations,  trade  unions  and  consumer  protection  organisations  in  the  design  and  development  of  AI systems,  and  diversity of  the  development  teams,  including  gender  balance.  To  ensure  that  the  voluntary codes  of conduct  are  effective,  they  should  be  based  on  clear  objectives  and  key  performance  indicators  to  measure  the achievement  of  those  objectives.  They  should  also  be  developed  in  an  inclusive  way,  as  appropriate,  with  the involvement of relevant stakeholders such as business and civil society organisations, academia, research organisations,  trade  unions  and  consumer  protection  organisation.  The  Commission  may  develop  initiatives, including of a sectoral nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of  data.
- (166) It is important that AI systems related to products that are not high-risk in accordance with this Regulation and thus are not required to comply with the requirements set out for high-risk AI systems are nevertheless safe when placed on  the  market  or  put  into  service.  To  contribute  to  this  objective,  Regulation  (EU)  2023/988  of  the  European Parliament  and  of  the  Council ( 53 )  would  apply  as  a  safety  net.
- (167) In  order  to  ensure  trustful  and  constructive  cooperation  of  competent  authorities  on  Union  and  national  level,  all parties  involved  in  the  application  of  this  Regulation  should  respect  the  confidentiality  of  information  and  data obtained in carrying out their tasks, in accordance with Union or national law. They should carry out their tasks and activities in such a manner as to protect, in particular, intellectual property rights, confidential business information and trade secrets, the effective implementation of this Regulation, public and national security interests, the integrity of  criminal  and  administrative  proceedings,  and  the  integrity of  classified  information.
- (168) Compliance  with  this  Regulation  should  be  enforceable  by  means  of  the  imposition  of  penalties  and  other enforcement  measures.  Member  States  should  take  all  necessary  measures  to  ensure  that  the  provisions  of  this Regulation  are  implemented,  including  by  laying  down  effective,  proportionate  and  dissuasive  penalties  for  their infringement,  and  to  respect  the ne  bis  in  idem principle.  In  order  to  strengthen  and  harmonise  administrative penalties for infringement of this Regulation, the upper limits for setting the administrative fines for certain specific infringements  should  be  laid  down.  When  assessing  the  amount  of  the  fines,  Member  States  should,  in  each individual case, take into account all relevant circumstances of the specific situation, with due regard in particular to the  nature,  gravity  and  duration  of  the  infringement  and  of  its  consequences  and  to  the  size  of  the  provider,  in particular if the provider is an SME, including a start-up. The European Data Protection Supervisor should have the power  to impose  fines  on  Union  institutions,  agencies  and  bodies  falling  within  the  scope  of  this  Regulation.
