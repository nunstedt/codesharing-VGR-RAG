## 2. OVERVIEW OF PROHIBITED AI PRACTICES
- (8) Article 5 AI Act prohibits the placing on the EU market, putting into service, or use of certain  AI  systems  for  manipulative,  exploitative,  social  control  or  surveillance practices, which by their inherent nature violate fundamental rights and Union values. Recital 28 AI Act clarifies that such practices are particularly harmful and abusive and should be prohibited because they contradict the Union values of respect for human dignity, freedom, equality, democracy, and the rule of law, as well as fundamental rights enshrined in the Charter of Fundamental Right of the European Union ( ' the Charter'), including the right to non-discrimination (Article 21 Charter) and equality (Article 20), data protection (Article 8 Charter) and private and family life (Article 7 Charter), and the rights of the child (Article 24 Charter). The prohibitions in Article 5 AI Act also aim to uphold the right to freedom of expression and information (Article 11 Charter), freedom  of  assembly  and  of  association  (Article  12  Charter),  freedom  of  thought, conscience and religion (Article 10 Charter), the right to an effective remedy and fair trial (Article 47 Charter), and the presumption of innocence and the right of defence (Article 48 Charter).
## . Prohibitions listed in Article 5 AI Act
## (9) Overview on the Prohibitions
| Provision       | Prohibition                             | Content                                                                                                                                                                                                                                                  |
|-----------------|-----------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Article 5(1)(a) | Harmful manipulation, and deception     | AI systems that deploy subliminal techniques beyond a person's consciousness or purposefully manipulative or deceptive techniques, with the objective or with the effect of distorting behaviour, causing or reasonably likely to cause significant harm |
| Article 5(1)(b) | Harmful exploitation of vulnerabilities | AI systems that exploit vulnerabilities due to age, disability or a specific social or economic situation, with the objective or with the effect of distorting behaviour, causing or reasonably likely to cause significant harm                         |
| Article 5(1)(c)   | Social scoring                                              | AI systems that evaluate or classify natural persons or groups of persons based on social behaviour or personal or personality characteristics, with the social score leading to detrimental or unfavourable treatment when data comes from unrelated social contexts or such treatment is unjustified or disproportionate to the social behaviour                                                             |
|-------------------|-------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Article 5(1)(d)   | Individual criminal offence risk assessment and prediction  | AI systems that assess or predict the risk of people committing a criminal offence based solely on profiling or personality traits and characteristics; except to support a human assessment based on objective and verifiable facts directly linked to a criminal activity                                                                                                                                    |
| Article 5(1)(e)   | Untargeted scraping to develop facial recognition databases | AI systems that create or expand facial recognition databases through untargeted scraping of facial images from the internet or closed-circuit television ( ' CCTV') footage                                                                                                                                                                                                                                   |
| Article 5(1)(f)   | Emotion recognition                                         | AI systems that infer emotions at the workplace or in education institutions; except for medical or safety reasons                                                                                                                                                                                                                                                                                             |
| Article 5(1)(g)   | Biometric categorisation                                    | AI systems that categorise people based on their biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs, sex-life or sexual orientation; except for labelling or filtering of lawfully acquired biometric datasets, including in the area of law enforcement                                                                             |
| Article 5(1)(h)   | Real-time remote biometric identification ('RBI')           | AI systems for real-time remote biometric identification in publicly accessible spaces for the purposes of law enforcement; except if necessary for the targeted search of specific victims, the prevention of specific threats including terrorist attacks, or the search of suspects of specific offences (further procedural requirements, including for authorisation, outlined in Article 5(2-7) AI Act). |
## . Legal basis of the prohibitions
(10) The AI Act is supported by two legal bases: Article 114 of the Treaty on the Functioning of the European Union ('TFEU') (the internal market legal basis) and Article 16 TFEU (the data protection legal basis). Article 16 TFEU serves as a legal basis for  the specific rules  on  the  processing  of  personal  data  in  relation  to  the  prohibition  on  the  use  of remote  biometric  identification  ('RBI')  systems  for  law  enforcement  purposes, biometric  categorisation  systems  for  law  enforcement  purposes,  and  individual  risk
assessments for law enforcement purposes. 4 All other prohibitions listed in Article 5 AI Act find their legal basis in Article 114 TFEU.
## . Material scope: practices related to the 'placing on the market', 'putting into service' or 'use' of an AI system
- (11) The practices prohibited by Article 5 AI Act relate to the placing on the market, the putting into service, or the use of specific AI systems. 5 As regards real-time remote biometric identification ('RBI') systems, the prohibition in Article 5(1)(h) AI Act only applies to their use. Article 3(1) AI Act defines what constitutes an AI system. The Guidelines on the Definition of an AI system provide the Commission's interpretation of that definition .
- (12) According to Article 3(9) AI Act, the placing on the market of an AI system is 'the first making available of an AI system [â€¦] on the Union market'. 'Making available' is defined as the supply of the system 'for distribution or use on the Union market in the course of a commercial activity, whether in return for payment or free of charge.' 6 The making available of an AI system is covered regardless of the means of supply, such  as  access  to  the  system  and  its  service  through  an  application  programming interface  ('API'),  via  cloud,  direct  downloads,  as  physical  copies,  or  embedded  in physical products.
For example, a RBI system developed outside the Union by a third-country provider is placed on the Union market for the first time when it is offered in return for payment or free of charge in one or more Member States. Such placing on the market may occur by providing access to the system online through an API or other user interface.
- (13) Article 3(11) AI Act defines putting into service as 'the supply of an AI system for first use to the deployer or for own use in the Union for its intended purpose', therefore covering both supply for first use to third parties, as well as in-house development and deployment. The intended purpose of the system is the 'use for which an AI system is intended  by  the  provider,  including  the  specific  context  and  conditions  of  use,  as specified  in  the  information  supplied  by  the  provider  in  the  instructions  of  use, promotional or sales materials and statements, as well as in the technical documentation.' 7
4 Recital 3 AI Act. Regarding the prohibitions based on Article 16 of the TFEU, there are two relevant opt outs for Ireland and Denmark. With the discretion granted to Ireland under Protocol No. 21 on the position of the United Kingdom and Ireland in the area of freedom, security and justice (AFSJ) annexed to the TEU and TFEU, Ireland may decide not to apply the rules concerning the prohibition of real-time use of RBIs in public spaces for a law enforcement purpose as well as the procedural rules linked to that article (Article 5(2) to (6) AI Act) (see Recital 40). 